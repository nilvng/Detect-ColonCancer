{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "955516c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import keras_tuner as kt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57761c43",
   "metadata": {},
   "source": [
    "### Load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b1deda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = pd.read_csv(\"Image_classification_data/data_labels_extraData.csv\")\n",
    "extra_data = pd.read_csv(\"Image_classification_data/data_labels_mainData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc53247b",
   "metadata": {},
   "source": [
    "### split data into different folders for different cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f240316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "root = os.getcwd()\n",
    "source_dir = os.path.join(root, \"patch_images\")\n",
    "\n",
    "for i, row in main_data.iterrows():\n",
    "    image_name = row[\"ImageName\"]\n",
    "    cell_name = row[\"cellTypeName\"]\n",
    "    is_cancer = str(row[\"isCancerous\"])\n",
    "\n",
    "#     new_folder_multi = os.path.join(root,\"multiclass_task\", cell_name)\n",
    "    new_folder_bin = os.path.join(root,\"binary_task\", is_cancer)\n",
    "\n",
    "#     os.makedirs(new_folder_multi, exist_ok=True)\n",
    "    os.makedirs(new_folder_bin, exist_ok=True)\n",
    "\n",
    "    source = os.path.join(source_dir, image_name)\n",
    "\n",
    "#     dest_multi = os.path.join(root, \"multiclass_task\",cell_name)\n",
    "    dest_bin = os.path.join(root,\"binary_task\", is_cancer)\n",
    "\n",
    "#     go = shutil.copy(source,dest_multi)\n",
    "    go = shutil.copy(source, dest_bin)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3890247e",
   "metadata": {},
   "source": [
    "### Add training data for cancerous classification from extra dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "682dc3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "root = os.getcwd()\n",
    "source_dir = os.path.join(root, \"patch_images\")\n",
    "\n",
    "for i, row in extra_data.iterrows():\n",
    "    image_name = row[\"ImageName\"]\n",
    "    is_cancer = str(row[\"isCancerous\"])\n",
    "\n",
    "    new_folder_bin = os.path.join(root, \"binary_task\",is_cancer)\n",
    "\n",
    "    os.makedirs(new_folder_bin, exist_ok=True)\n",
    "\n",
    "    source = os.path.join(source_dir, image_name)\n",
    "\n",
    "    dest_bin = os.path.join(root, is_cancer)\n",
    "\n",
    "    go = shutil.copy(source, dest_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857e51b4",
   "metadata": {},
   "source": [
    "### Old load image code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b6669fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9896\n",
      "9896\n",
      "9896\n"
     ]
    }
   ],
   "source": [
    "def get_images(img_list, path):    \n",
    "    images = list()\n",
    "    \n",
    "    for img in img_list:\n",
    "        img = cv2.imread(os.path.join(path, img))\n",
    "        # resize to 0-1 for faster computation\n",
    "        resized = img / 255\n",
    "        images.append(resized)\n",
    "        \n",
    "    return images\n",
    "\n",
    "images, cell_type, is_cancerous = get_images(main_data[\"ImageName\"], \"patch_images\"), main_data[[\"cellType\"]], main_data[[\"isCancerous\"]]\n",
    "\n",
    "print(len(images))\n",
    "#print(images[0].shape)\n",
    "print(len(cell_type))\n",
    "print(len(is_cancerous))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e5727f",
   "metadata": {},
   "source": [
    "### Get data from splitted folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c986143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "root = os.getcwd()\n",
    "source_dir = os.path.join(root, \"patch_images\")\n",
    "\n",
    "def cancerous_classify_data():    \n",
    "    images = list()\n",
    "    labels = list()\n",
    "    \n",
    "    for label in [0, 1]:\n",
    "        # get image directory\n",
    "        img_dir = os.path.join(root, \"binary_task\",f\"{label}\")\n",
    "        \n",
    "        for img in os.listdir(img_dir):\n",
    "            img = cv2.imread(os.path.join(img_dir, img))\n",
    "            # resize to 0-1 for faster computation\n",
    "            resized = img / 255\n",
    "            images.append(resized)\n",
    "            labels.append(label)\n",
    "        \n",
    "    return (images, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b14344",
   "metadata": {},
   "source": [
    "### Data augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed3266f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "root = os.getcwd()\n",
    "binary_root = os.path.join(root, \"binary_task\")\n",
    "multiclass_root = os.path.join(root, \"multiclass_task\")\n",
    "\n",
    "datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9977c54a",
   "metadata": {},
   "source": [
    "### Base CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19f550aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/keras_preprocessing/image/image_data_generator.py:337: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 11:49:18.572060: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248/248 [==============================] - ETA: 0s - loss: 0.4474 - accuracy: 0.7828 - auc: 0.8660"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 11:49:36.971005: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248/248 [==============================] - 22s 87ms/step - loss: 0.4474 - accuracy: 0.7828 - auc: 0.8660 - val_loss: 0.3668 - val_accuracy: 0.8384 - val_auc: 0.9309\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 20s 81ms/step - loss: 0.2936 - accuracy: 0.8766 - auc: 0.9458 - val_loss: 0.3352 - val_accuracy: 0.8667 - val_auc: 0.9374\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 23s 92ms/step - loss: 0.2593 - accuracy: 0.8925 - auc: 0.9576 - val_loss: 0.3495 - val_accuracy: 0.8470 - val_auc: 0.9382\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 25s 102ms/step - loss: 0.2306 - accuracy: 0.9054 - auc: 0.9662 - val_loss: 0.3402 - val_accuracy: 0.8682 - val_auc: 0.9381\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 21s 84ms/step - loss: 0.2061 - accuracy: 0.9224 - auc: 0.9726 - val_loss: 0.3511 - val_accuracy: 0.8747 - val_auc: 0.9377\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 22s 87ms/step - loss: 0.1742 - accuracy: 0.9325 - auc: 0.9806 - val_loss: 0.3602 - val_accuracy: 0.8707 - val_auc: 0.9365\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 20s 79ms/step - loss: 0.1584 - accuracy: 0.9367 - auc: 0.9842 - val_loss: 0.3830 - val_accuracy: 0.8611 - val_auc: 0.9315\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 21s 86ms/step - loss: 0.1270 - accuracy: 0.9526 - auc: 0.9896 - val_loss: 0.4107 - val_accuracy: 0.8697 - val_auc: 0.9289\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 31s 124ms/step - loss: 0.1123 - accuracy: 0.9539 - auc: 0.9920 - val_loss: 0.4656 - val_accuracy: 0.8510 - val_auc: 0.9287\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 25s 101ms/step - loss: 0.0760 - accuracy: 0.9726 - auc: 0.9964 - val_loss: 0.7425 - val_accuracy: 0.8470 - val_auc: 0.9024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c7d2ef40>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, cancer_label = cancerous_classify_data()\n",
    "\n",
    "# try testing cancerous dataset\n",
    "# x_train, x_test, y_train, y_test = train_test_split(\n",
    "#     np.array(images), np.array(is_cancerous), test_size=0.2\n",
    "# )\n",
    "\n",
    "def get_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    # First convo-pooling\n",
    "    # Convolutional layers (filter the image with a kernel)\n",
    "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=[27, 27, 3]))\n",
    "    # Max-pooling layers (reduce the size of the image by choosing max pixel at certain area)\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    # Flatten input\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    # Compile model\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\", \"AUC\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# train data from manual load data\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    np.array(images), np.array(cancer_label), test_size=0.2\n",
    ")\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    zca_whitening=True,\n",
    ")\n",
    "datagen.fit(np.array(images))\n",
    "\n",
    "aug_train = datagen.flow(x_train, y_train, shuffle=True)\n",
    "aug_val = datagen.flow(x_test, y_test, shuffle=True)\n",
    "\n",
    "model = get_model()\n",
    "# model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "model.fit(aug_train, epochs=10, validation_data=aug_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6888d1",
   "metadata": {},
   "source": [
    "### Tune CNN model\n",
    "\n",
    "Tunable parameters:\n",
    "- Size of kernel of Convolution/Pooling Layers\n",
    "- Strides of Convolution/Pooling Layers\n",
    "- Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2edb288b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 30s]\n",
      "val_accuracy: 0.596969723701477\n",
      "\n",
      "Best val_accuracy So Far: 0.8808081150054932\n",
      "Total elapsed time: 00h 01m 54s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    np.array(images), np.array(cancer_label), test_size=0.2\n",
    ")\n",
    "\n",
    "def cnn_tuner(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    for i in range(hp.Int(f'no_cnn', 1, 4, step=1)):\n",
    "        # Convolutional layers (filter the image with a kernel)\n",
    "        model.add(tf.keras.layers.Conv2D(hp.Int(f'convo_filter_{i}', 16, 128, step=16), (3, 3), strides=1,activation=hp.Choice(f\"activation_convo_{i}\", [\"relu\", \"sigmoid\", \"softmax\", \"tanh\"]), input_shape=[27, 27, 3]))\n",
    "        # Max-pooling layers (reduce the size of the image by choosing max pixel at certain area)\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=1,))\n",
    "        \n",
    "    # Flatten input\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    # hidden layers\n",
    "    for i in range(hp.Int('layers_no', 1, 4)):\n",
    "        model.add(tf.keras.layers.Dense(hp.Int(f'hidden_layer_{i}', 32, 256, step=32), activation=hp.Choice(f\"activation_hidden_{i}\", [\"relu\", \"sigmoid\", \"softmax\", \"tanh\"])))\n",
    "        \n",
    "    # output layer\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))   \n",
    "    # Compile model\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\", \"AUC\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# status.expect_partial()\n",
    "              \n",
    "tuner = kt.RandomSearch(cnn_tuner, objective=\"val_accuracy\", max_trials=5)\n",
    "\n",
    "tuner.search(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "best_model = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "075833c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Convolution filter: 96\n",
      "Best number of hidden layer: 160\n",
      "Best nodes in hidden layer 0: 160\n",
      "Best activation in hidden layer 0: sigmoid\n",
      "Best nodes in hidden layer 1: 160\n",
      "Best activation in hidden layer 1: tanh\n",
      "Best nodes in hidden layer 2: 160\n",
      "Best activation in hidden layer 2: sigmoid\n",
      "Best nodes in hidden layer 3: 160\n",
      "Best activation in hidden layer 3: relu\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Convolution filter: {tuner.get_best_hyperparameters()[0].get('convo_filter')}\")\n",
    "print(f\"Best number of hidden layer: {tuner.get_best_hyperparameters()[0].get('hidden_layer')}\")\n",
    "\n",
    "for i in range(tuner.get_best_hyperparameters()[0].get('cnn_no')):\n",
    "    print(f\"Best filter in CNN layer {i}: {tuner.get_best_hyperparameters()[0].get(f'convo_filter_{i}')}\")\n",
    "    print(f\"Best filter in CNN layer {i}: {tuner.get_best_hyperparameters()[0].get(f\"activation_convo_{i}\")\n",
    "\n",
    "for i in range(tuner.get_best_hyperparameters()[0].get('layers_no')):\n",
    "    print(f\"Best nodes in hidden layer {i}: {tuner.get_best_hyperparameters()[0].get(f'hidden_layer_{i}')}\")\n",
    "    print(f\"Best activation in hidden layer {i}: {tuner.get_best_hyperparameters()[0].get(f'activation_hidden_{i}')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01340ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 13:15:50.902990: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/507 [============================>.] - ETA: 0s - loss: 0.3040 - accuracy: 0.8665 - auc: 0.9364"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 13:15:56.659471: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507/507 [==============================] - 7s 13ms/step - loss: 0.3041 - accuracy: 0.8667 - auc: 0.9364 - val_loss: 0.3408 - val_accuracy: 0.8474 - val_auc: 0.9363\n",
      "Epoch 2/10\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.2892 - accuracy: 0.8739 - auc: 0.9425 - val_loss: 0.3483 - val_accuracy: 0.8614 - val_auc: 0.9390\n",
      "Epoch 3/10\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.2661 - accuracy: 0.8876 - auc: 0.9514 - val_loss: 0.3096 - val_accuracy: 0.8728 - val_auc: 0.9376\n",
      "Epoch 4/10\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.2448 - accuracy: 0.8935 - auc: 0.9590 - val_loss: 0.4050 - val_accuracy: 0.8425 - val_auc: 0.9346\n",
      "Epoch 5/10\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.2220 - accuracy: 0.9077 - auc: 0.9662 - val_loss: 0.3574 - val_accuracy: 0.8627 - val_auc: 0.9325\n",
      "Epoch 6/10\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.1984 - accuracy: 0.9173 - auc: 0.9731 - val_loss: 0.3761 - val_accuracy: 0.8508 - val_auc: 0.9318\n",
      "Epoch 7/10\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.1664 - accuracy: 0.9334 - auc: 0.9809 - val_loss: 0.3838 - val_accuracy: 0.8688 - val_auc: 0.9231\n",
      "Epoch 8/10\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.1456 - accuracy: 0.9421 - auc: 0.9852 - val_loss: 0.3927 - val_accuracy: 0.8698 - val_auc: 0.9295\n",
      "Epoch 9/10\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.1294 - accuracy: 0.9476 - auc: 0.9881 - val_loss: 0.3855 - val_accuracy: 0.8644 - val_auc: 0.9291\n",
      "Epoch 10/10\n",
      "507/507 [==============================] - 6s 12ms/step - loss: 0.1074 - accuracy: 0.9589 - auc: 0.9916 - val_loss: 0.4712 - val_accuracy: 0.8649 - val_auc: 0.9173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x323a0cca0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e5992e",
   "metadata": {},
   "source": [
    "### Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bc84924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 12:29:02.441814: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502/507 [============================>.] - ETA: 0s - loss: 0.4035 - accuracy: 0.8150 - auc: 0.8832"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 12:29:07.267409: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507/507 [==============================] - 6s 11ms/step - loss: 0.4023 - accuracy: 0.8155 - auc: 0.8839 - val_loss: 0.3566 - val_accuracy: 0.8481 - val_auc: 0.9196\n",
      "Epoch 2/5\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.3472 - accuracy: 0.8513 - auc: 0.9155 - val_loss: 0.4497 - val_accuracy: 0.7894 - val_auc: 0.9224\n",
      "Epoch 3/5\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.3271 - accuracy: 0.8634 - auc: 0.9255 - val_loss: 0.3253 - val_accuracy: 0.8609 - val_auc: 0.9320\n",
      "Epoch 4/5\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.3061 - accuracy: 0.8726 - auc: 0.9345 - val_loss: 0.3085 - val_accuracy: 0.8688 - val_auc: 0.9371\n",
      "Epoch 5/5\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.2996 - accuracy: 0.8755 - auc: 0.9376 - val_loss: 0.3480 - val_accuracy: 0.8543 - val_auc: 0.9352\n",
      "Epoch 1/5\n",
      "  1/507 [..............................] - ETA: 2:36 - loss: 0.6759 - accuracy: 0.5938 - auc: 0.6053"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 12:29:27.537301: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/507 [============================>.] - ETA: 0s - loss: 0.4187 - accuracy: 0.8018 - auc: 0.8733"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 12:29:31.934386: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507/507 [==============================] - 5s 10ms/step - loss: 0.4183 - accuracy: 0.8020 - auc: 0.8736 - val_loss: 0.3767 - val_accuracy: 0.8323 - val_auc: 0.9160\n",
      "Epoch 2/5\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.3408 - accuracy: 0.8543 - auc: 0.9189 - val_loss: 0.3306 - val_accuracy: 0.8590 - val_auc: 0.9262\n",
      "Epoch 3/5\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.3263 - accuracy: 0.8611 - auc: 0.9258 - val_loss: 0.3197 - val_accuracy: 0.8664 - val_auc: 0.9308\n",
      "Epoch 4/5\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.3099 - accuracy: 0.8705 - auc: 0.9332 - val_loss: 0.3471 - val_accuracy: 0.8531 - val_auc: 0.9297\n",
      "Epoch 5/5\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.3007 - accuracy: 0.8736 - auc: 0.9373 - val_loss: 0.3209 - val_accuracy: 0.8632 - val_auc: 0.9362\n",
      "Epoch 1/5\n",
      "  1/507 [..............................] - ETA: 2:38 - loss: 0.6501 - accuracy: 0.7188 - auc: 0.6473"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 12:29:52.092467: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507/507 [==============================] - ETA: 0s - loss: 0.3943 - accuracy: 0.8187 - auc: 0.8893"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 12:29:56.532275: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507/507 [==============================] - 5s 10ms/step - loss: 0.3943 - accuracy: 0.8187 - auc: 0.8893 - val_loss: 0.3908 - val_accuracy: 0.8222 - val_auc: 0.9181\n",
      "Epoch 2/5\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.3409 - accuracy: 0.8515 - auc: 0.9188 - val_loss: 0.3395 - val_accuracy: 0.8540 - val_auc: 0.9244\n",
      "Epoch 3/5\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.3256 - accuracy: 0.8600 - auc: 0.9261 - val_loss: 0.3995 - val_accuracy: 0.8257 - val_auc: 0.9281\n",
      "Epoch 4/5\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.3121 - accuracy: 0.8705 - auc: 0.9322 - val_loss: 0.4551 - val_accuracy: 0.7944 - val_auc: 0.9304\n",
      "Epoch 5/5\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.2986 - accuracy: 0.8746 - auc: 0.9381 - val_loss: 0.3361 - val_accuracy: 0.8543 - val_auc: 0.9338\n",
      "Epoch 1/5\n",
      "  1/507 [..............................] - ETA: 2:36 - loss: 0.6376 - accuracy: 0.7812 - auc: 0.6771"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 12:30:16.958711: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/507 [============================>.] - ETA: 0s - loss: 0.4108 - accuracy: 0.8136 - auc: 0.8789"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 12:30:21.261002: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507/507 [==============================] - 5s 10ms/step - loss: 0.4106 - accuracy: 0.8138 - auc: 0.8789 - val_loss: 0.3663 - val_accuracy: 0.8432 - val_auc: 0.9141\n",
      "Epoch 2/5\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.3464 - accuracy: 0.8497 - auc: 0.9162 - val_loss: 0.3438 - val_accuracy: 0.8531 - val_auc: 0.9204\n",
      "Epoch 3/5\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.3312 - accuracy: 0.8572 - auc: 0.9237 - val_loss: 0.4029 - val_accuracy: 0.8129 - val_auc: 0.9269\n",
      "Epoch 4/5\n",
      "507/507 [==============================] - 5s 9ms/step - loss: 0.3136 - accuracy: 0.8658 - auc: 0.9317 - val_loss: 0.3340 - val_accuracy: 0.8484 - val_auc: 0.9341\n",
      "Epoch 5/5\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.3033 - accuracy: 0.8715 - auc: 0.9362 - val_loss: 0.3656 - val_accuracy: 0.8452 - val_auc: 0.9314\n",
      "Epoch 1/5\n",
      "  1/507 [..............................] - ETA: 2:51 - loss: 0.6469 - accuracy: 0.7500 - auc: 0.5990"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 12:30:41.839497: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502/507 [============================>.] - ETA: 0s - loss: 0.4079 - accuracy: 0.8134 - auc: 0.8805"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 12:30:46.377667: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507/507 [==============================] - 6s 10ms/step - loss: 0.4075 - accuracy: 0.8141 - auc: 0.8808 - val_loss: 0.3662 - val_accuracy: 0.8390 - val_auc: 0.9201\n",
      "Epoch 2/5\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.3458 - accuracy: 0.8499 - auc: 0.9162 - val_loss: 0.3440 - val_accuracy: 0.8523 - val_auc: 0.9224\n",
      "Epoch 3/5\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.3267 - accuracy: 0.8606 - auc: 0.9255 - val_loss: 0.3220 - val_accuracy: 0.8644 - val_auc: 0.9308\n",
      "Epoch 4/5\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.3026 - accuracy: 0.8702 - auc: 0.9363 - val_loss: 0.3158 - val_accuracy: 0.8698 - val_auc: 0.9339\n",
      "Epoch 5/5\n",
      "507/507 [==============================] - 5s 10ms/step - loss: 0.2974 - accuracy: 0.8759 - auc: 0.9384 - val_loss: 0.3303 - val_accuracy: 0.8656 - val_auc: 0.9305\n"
     ]
    }
   ],
   "source": [
    "# generate train and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(np.array(images), np.array(cancer_label), test_size=0.2)\n",
    "\n",
    "# train data from ImageDataGenerator\n",
    "aug_train = image_dataset_from_directory(binary_root, labels=\"inferred\",validation_split=0.2,\n",
    "  subset=\"training\",seed=123, image_size=(27,27))\n",
    "aug_val = image_dataset_from_directory(binary_root, labels=\"inferred\",validation_split=0.2,\n",
    "  subset=\"validation\",seed=123,  image_size=(27,27))\n",
    "\n",
    "# intialize and train sub-models\n",
    "def get_sub_model():\n",
    "    # number of sub models\n",
    "    nets = 5\n",
    "    sub_models = [0]*nets\n",
    "    \n",
    "    for i in range(nets):\n",
    "        model = get_model()\n",
    "        # fit sub_model with train and test data\n",
    "        model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "        \n",
    "        # save fitted sub_model to model list\n",
    "        sub_models[i] = model\n",
    "        \n",
    "    return sub_models\n",
    "    \n",
    "sub_models = get_sub_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e90d20eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to get output from submodels to feed meta_learner\n",
    "# shape of dataset would be (no rows of OG dataset, [no output of sub model * no sub model])\n",
    "def get_ensembled_x(x):\n",
    "    ensembled_data = None\n",
    "    for sub_model in sub_models:\n",
    "        prediction = sub_model.predict(x)\n",
    "        \n",
    "        # stack prediction of sub model to ensembled data\n",
    "        if ensembled_data is None:\n",
    "            ensembled_data = prediction\n",
    "        else:\n",
    "            ensembled_data = np.dstack((ensembled_data, prediction))\n",
    "            \n",
    "    # ensemble data initially shape iz (no_col, no submodels, no classes)        \n",
    "    # reshape to (no_col, no submodels*no classes)\n",
    "    ensembled_data = ensembled_data.reshape(ensembled_data.shape[0], ensembled_data.shape[1]*ensembled_data.shape[2])\n",
    "    return ensembled_data\n",
    "\n",
    "def get_meta_learner():\n",
    "    model = tf.keras.Sequential()\n",
    "    # Flatten input\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    # Hidden layers\n",
    "    model.add(tf.keras.layers.Dense(256, activation=\"tanh\"))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=\"softmax\"))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    # Compile model\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\", \"AUC\"])\n",
    "    \n",
    "    # get train ensembled data\n",
    "    ensembled_x = get_ensembled_x(x_train)\n",
    "    \n",
    "    model.fit(ensembled_x, y_train, epochs=10)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b341ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 12:31:14.316182: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-03 12:31:14.592216: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-03 12:31:14.857777: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-03 12:31:15.125754: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-03 12:31:15.393551: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-03 12:31:15.748085: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-03 12:31:16.835260: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-03 12:31:17.800838: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-03 12:31:18.874799: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-03 12:31:19.863718: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 12:31:20.944978: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507/507 [==============================] - 4s 8ms/step - loss: 0.3601 - accuracy: 0.8763 - auc: 0.9177\n",
      "Epoch 2/10\n",
      "507/507 [==============================] - 4s 7ms/step - loss: 0.2748 - accuracy: 0.8889 - auc: 0.9486\n",
      "Epoch 3/10\n",
      "507/507 [==============================] - 4s 7ms/step - loss: 0.2718 - accuracy: 0.8903 - auc: 0.9498\n",
      "Epoch 4/10\n",
      "507/507 [==============================] - 4s 7ms/step - loss: 0.2711 - accuracy: 0.8901 - auc: 0.9496\n",
      "Epoch 5/10\n",
      "507/507 [==============================] - 4s 7ms/step - loss: 0.2700 - accuracy: 0.8904 - auc: 0.9500\n",
      "Epoch 6/10\n",
      "507/507 [==============================] - 4s 7ms/step - loss: 0.2694 - accuracy: 0.8897 - auc: 0.9499\n",
      "Epoch 7/10\n",
      "507/507 [==============================] - 4s 7ms/step - loss: 0.2690 - accuracy: 0.8907 - auc: 0.9501\n",
      "Epoch 8/10\n",
      "507/507 [==============================] - 4s 7ms/step - loss: 0.2687 - accuracy: 0.8896 - auc: 0.9502\n",
      "Epoch 9/10\n",
      "507/507 [==============================] - 4s 7ms/step - loss: 0.2685 - accuracy: 0.8895 - auc: 0.9501\n",
      "Epoch 10/10\n",
      "507/507 [==============================] - 4s 8ms/step - loss: 0.2692 - accuracy: 0.8894 - auc: 0.9499\n",
      "  1/127 [..............................] - ETA: 28s - loss: 0.2177 - accuracy: 0.9062 - auc: 0.9543"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 12:31:59.237369: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 1s 7ms/step - loss: 0.3076 - accuracy: 0.8691 - auc: 0.9365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3075993061065674, 0.8690828680992126, 0.936511218547821]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate with ensembled CNN model\n",
    "# get test data\n",
    "ensembled_x_test = get_ensembled_x(x_test)\n",
    "# get trained ensemble model\n",
    "ensembled_model = get_meta_learner()\n",
    "# evaluate\n",
    "ensembled_model.evaluate(ensembled_x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8319ef",
   "metadata": {},
   "source": [
    "### Base model for multiclass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f04400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def celltype_classify_data(class_list, root):    \n",
    "    images = list()\n",
    "    labels = list()\n",
    "    \n",
    "    for i, label in enumerate(class_list):\n",
    "        # get image directory\n",
    "        img_dir = os.path.join(root, f\"{label}\")\n",
    "        \n",
    "        for img in os.listdir(img_dir):\n",
    "            img = cv2.imread(os.path.join(img_dir, img))\n",
    "            # resize to 0-1 for faster computation\n",
    "            resized = img / 255\n",
    "            images.append(resized)\n",
    "            labels.append(i)\n",
    "        \n",
    "    return (images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02bfbb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_multiclass_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    # First convo-pooling\n",
    "    \n",
    "    # Convolutional layers (filter the image with a kernel)\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), strides=1,activation=\"relu\", input_shape=[27, 27, 3]))\n",
    "    # Max-pooling layers (reduce the size of the image by choosing max pixel at certain area)\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=1))\n",
    "    \n",
    "    # Convolutional layers (filter the image with a kernel)\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3),strides=1, activation=\"relu\"))\n",
    "    # Max-pooling layers (reduce the size of the image by choosing max pixel at certain area)\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2),strides=1))\n",
    "    \n",
    "    # Flatten input\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(4, activation=\"softmax\"))\n",
    "    # Compile model \n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3409180",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ks/c7f10mrs12z35r1mm8xqv_zh0000gn/T/ipykernel_67034/39339156.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHIAAABvCAYAAAAwlZQ4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAABYElEQVR4nO3UwU0DUQxAwf2IEsKZ7b+WpIicoQfTQFBYKRHwNHO1D5ae5DUzG//fy28fwGMIGSFkhJARQkYIGfF6ZPl0Os2+7086hXsul8vnzLzdmh0Kue/7dj6fH3MVh621rt/NvNYIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjBAyQsgIISOEjFgz8/PltT62bbs+7xzueJ+Zt1uDQyH5u7zWCCEjhIwQMkLICCEjhIwQMkLIiC8Hohp/BhBaQAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "all_class = [\"epithelial\", \"fibroblast\", \"inflammatory\", \"others\"]\n",
    "\n",
    "# print first 25 images\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(all_class[y_train[i]])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "cell_img, celltype_label = celltype_classify_data(all_class)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    np.array(cell_img), np.array(celltype_label), test_size=0.2\n",
    ")\n",
    "\n",
    "model = get_multiclass_model()\n",
    "\n",
    "model.fit(x_train, y_train, epochs=15, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59cfe83",
   "metadata": {},
   "source": [
    "Base CNN + ZCA whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d5d5373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 12:38:04.478584: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248/248 [==============================] - ETA: 0s - loss: 1.3706 - accuracy: 0.4061"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 12:38:23.959164: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248/248 [==============================] - 23s 91ms/step - loss: 1.3706 - accuracy: 0.4061 - val_loss: 1.2991 - val_accuracy: 0.4202\n",
      "Epoch 2/20\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.3081 - accuracy: 0.4102 - val_loss: 1.2988 - val_accuracy: 0.4202\n",
      "Epoch 3/20\n",
      "248/248 [==============================] - 21s 86ms/step - loss: 1.2966 - accuracy: 0.4102 - val_loss: 1.2720 - val_accuracy: 0.4763\n",
      "Epoch 4/20\n",
      "248/248 [==============================] - 21s 86ms/step - loss: 1.0521 - accuracy: 0.5394 - val_loss: 1.0167 - val_accuracy: 0.5475\n",
      "Epoch 5/20\n",
      "248/248 [==============================] - 23s 92ms/step - loss: 0.9413 - accuracy: 0.5918 - val_loss: 0.9600 - val_accuracy: 0.5859\n",
      "Epoch 6/20\n",
      "248/248 [==============================] - 22s 90ms/step - loss: 0.8677 - accuracy: 0.6290 - val_loss: 0.9248 - val_accuracy: 0.5985\n",
      "Epoch 7/20\n",
      "248/248 [==============================] - 22s 88ms/step - loss: 0.8128 - accuracy: 0.6572 - val_loss: 0.9588 - val_accuracy: 0.5848\n",
      "Epoch 8/20\n",
      "248/248 [==============================] - 22s 87ms/step - loss: 0.7303 - accuracy: 0.6937 - val_loss: 1.0056 - val_accuracy: 0.5833\n",
      "Epoch 9/20\n",
      "248/248 [==============================] - 22s 89ms/step - loss: 0.6330 - accuracy: 0.7423 - val_loss: 1.0920 - val_accuracy: 0.5783\n",
      "Epoch 10/20\n",
      "248/248 [==============================] - 21s 86ms/step - loss: 0.5032 - accuracy: 0.7976 - val_loss: 1.2448 - val_accuracy: 0.5707\n",
      "Epoch 11/20\n",
      "248/248 [==============================] - 22s 87ms/step - loss: 0.3851 - accuracy: 0.8552 - val_loss: 1.3937 - val_accuracy: 0.5591\n",
      "Epoch 12/20\n",
      "248/248 [==============================] - 21s 84ms/step - loss: 0.2886 - accuracy: 0.8935 - val_loss: 1.9989 - val_accuracy: 0.5631\n",
      "Epoch 13/20\n",
      "248/248 [==============================] - 22s 87ms/step - loss: 0.2185 - accuracy: 0.9219 - val_loss: 2.2358 - val_accuracy: 0.5545\n",
      "Epoch 14/20\n",
      "248/248 [==============================] - 22s 88ms/step - loss: 0.1547 - accuracy: 0.9450 - val_loss: 2.3432 - val_accuracy: 0.5495\n",
      "Epoch 15/20\n",
      "248/248 [==============================] - 23s 91ms/step - loss: 0.1620 - accuracy: 0.9468 - val_loss: 2.6337 - val_accuracy: 0.5621\n",
      "Epoch 16/20\n",
      "248/248 [==============================] - 23s 93ms/step - loss: 0.1132 - accuracy: 0.9627 - val_loss: 2.6724 - val_accuracy: 0.5480\n",
      "Epoch 17/20\n",
      "248/248 [==============================] - 23s 93ms/step - loss: 0.0534 - accuracy: 0.9851 - val_loss: 3.0535 - val_accuracy: 0.5475\n",
      "Epoch 18/20\n",
      "248/248 [==============================] - 22s 88ms/step - loss: 0.0713 - accuracy: 0.9771 - val_loss: 3.2356 - val_accuracy: 0.5470\n",
      "Epoch 19/20\n",
      "248/248 [==============================] - 23s 93ms/step - loss: 0.1166 - accuracy: 0.9597 - val_loss: 2.8625 - val_accuracy: 0.5576\n",
      "Epoch 20/20\n",
      "248/248 [==============================] - 21s 86ms/step - loss: 0.0812 - accuracy: 0.9749 - val_loss: 3.1996 - val_accuracy: 0.5424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c7f030a0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data from ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "     zca_whitening=True,\n",
    ")\n",
    "datagen.fit(np.array(cell_img))\n",
    "\n",
    "aug_train = datagen.flow(x_train, y_train, shuffle=True)\n",
    "aug_val = datagen.flow(x_test, y_test, shuffle=True)\n",
    "\n",
    "model = get_multiclass_model()\n",
    "model.fit(aug_train, epochs=20, validation_data=aug_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c230a95",
   "metadata": {},
   "source": [
    "Base CNN + rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "765a8e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 12:25:33.117577: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248/248 [==============================] - ETA: 0s - loss: 1.0627 - accuracy: 0.5485"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 12:25:36.867577: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248/248 [==============================] - 4s 16ms/step - loss: 1.0627 - accuracy: 0.5485 - val_loss: 0.9035 - val_accuracy: 0.6404\n",
      "Epoch 2/20\n",
      "248/248 [==============================] - 4s 15ms/step - loss: 0.8048 - accuracy: 0.6772 - val_loss: 0.7946 - val_accuracy: 0.6823\n",
      "Epoch 3/20\n",
      "248/248 [==============================] - 4s 15ms/step - loss: 0.7569 - accuracy: 0.6988 - val_loss: 0.7558 - val_accuracy: 0.7005\n",
      "Epoch 4/20\n",
      "248/248 [==============================] - 4s 15ms/step - loss: 0.7456 - accuracy: 0.6987 - val_loss: 0.7611 - val_accuracy: 0.6995\n",
      "Epoch 5/20\n",
      "248/248 [==============================] - 4s 15ms/step - loss: 0.7319 - accuracy: 0.7068 - val_loss: 0.8100 - val_accuracy: 0.6793\n",
      "Epoch 6/20\n",
      "248/248 [==============================] - 4s 15ms/step - loss: 0.7095 - accuracy: 0.7121 - val_loss: 0.6961 - val_accuracy: 0.7303\n",
      "Epoch 7/20\n",
      "248/248 [==============================] - 4s 15ms/step - loss: 0.7107 - accuracy: 0.7140 - val_loss: 0.7549 - val_accuracy: 0.6980\n",
      "Epoch 8/20\n",
      "248/248 [==============================] - 4s 15ms/step - loss: 0.7022 - accuracy: 0.7202 - val_loss: 0.6825 - val_accuracy: 0.7328\n",
      "Epoch 9/20\n",
      "248/248 [==============================] - 4s 15ms/step - loss: 0.6732 - accuracy: 0.7290 - val_loss: 0.7120 - val_accuracy: 0.7222\n",
      "Epoch 10/20\n",
      "248/248 [==============================] - 4s 15ms/step - loss: 0.6668 - accuracy: 0.7377 - val_loss: 0.6725 - val_accuracy: 0.7455\n",
      "Epoch 11/20\n",
      "248/248 [==============================] - 4s 15ms/step - loss: 0.6629 - accuracy: 0.7359 - val_loss: 0.7065 - val_accuracy: 0.7237\n",
      "Epoch 12/20\n",
      "248/248 [==============================] - 4s 15ms/step - loss: 0.6522 - accuracy: 0.7417 - val_loss: 0.7024 - val_accuracy: 0.7404\n",
      "Epoch 13/20\n",
      "248/248 [==============================] - 4s 15ms/step - loss: 0.6275 - accuracy: 0.7552 - val_loss: 0.6728 - val_accuracy: 0.7394\n",
      "Epoch 14/20\n",
      "248/248 [==============================] - 4s 15ms/step - loss: 0.6185 - accuracy: 0.7593 - val_loss: 0.6590 - val_accuracy: 0.7455\n",
      "Epoch 15/20\n",
      "248/248 [==============================] - 4s 15ms/step - loss: 0.6341 - accuracy: 0.7497 - val_loss: 0.6838 - val_accuracy: 0.7354\n",
      "Epoch 16/20\n",
      "248/248 [==============================] - 4s 15ms/step - loss: 0.5999 - accuracy: 0.7621 - val_loss: 0.6787 - val_accuracy: 0.7419\n",
      "Epoch 17/20\n",
      "248/248 [==============================] - 4s 15ms/step - loss: 0.6013 - accuracy: 0.7663 - val_loss: 0.7027 - val_accuracy: 0.7419\n",
      "Epoch 18/20\n",
      "248/248 [==============================] - 4s 15ms/step - loss: 0.5986 - accuracy: 0.7681 - val_loss: 0.6810 - val_accuracy: 0.7429\n",
      "Epoch 19/20\n",
      "248/248 [==============================] - 4s 15ms/step - loss: 0.5991 - accuracy: 0.7645 - val_loss: 0.6697 - val_accuracy: 0.7566\n",
      "Epoch 20/20\n",
      "248/248 [==============================] - 4s 15ms/step - loss: 0.5770 - accuracy: 0.7743 - val_loss: 0.7469 - val_accuracy: 0.7157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c7ffa070>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data from ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "     rotation_range=45,\n",
    ")\n",
    "datagen.fit(np.array(cell_img))\n",
    "\n",
    "aug_train = datagen.flow(x_train, y_train, shuffle=True)\n",
    "aug_val = datagen.flow(x_test, y_test, shuffle=True)\n",
    "\n",
    "model = get_multiclass_model()\n",
    "model.fit(aug_train, epochs=20, validation_data=aug_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ada6a38",
   "metadata": {},
   "source": [
    "### Multiclass using multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb8d3e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Subclass training---\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f9c345d7e60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f9c345d7e60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "213/213 [==============================] - ETA: 0s - loss: 0.6884 - accuracy: 0.7065WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f9c49334cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f9c49334cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "213/213 [==============================] - 7s 28ms/step - loss: 0.6884 - accuracy: 0.7065 - val_loss: 0.4964 - val_accuracy: 0.8067\n",
      "Epoch 2/15\n",
      "213/213 [==============================] - 6s 28ms/step - loss: 0.4895 - accuracy: 0.8061 - val_loss: 0.4785 - val_accuracy: 0.8102\n",
      "Epoch 3/15\n",
      "213/213 [==============================] - 6s 27ms/step - loss: 0.4681 - accuracy: 0.8140 - val_loss: 0.7592 - val_accuracy: 0.7150\n",
      "Epoch 4/15\n",
      "213/213 [==============================] - 7s 32ms/step - loss: 0.4597 - accuracy: 0.8243 - val_loss: 0.4615 - val_accuracy: 0.8102\n",
      "Epoch 5/15\n",
      "213/213 [==============================] - 7s 33ms/step - loss: 0.4151 - accuracy: 0.8434 - val_loss: 0.5068 - val_accuracy: 0.8032\n",
      "Epoch 6/15\n",
      "213/213 [==============================] - 6s 30ms/step - loss: 0.3858 - accuracy: 0.8543 - val_loss: 0.4407 - val_accuracy: 0.8296\n",
      "Epoch 7/15\n",
      "213/213 [==============================] - 6s 27ms/step - loss: 0.3656 - accuracy: 0.8540 - val_loss: 0.5026 - val_accuracy: 0.8132\n",
      "Epoch 8/15\n",
      "213/213 [==============================] - 7s 32ms/step - loss: 0.3486 - accuracy: 0.8656 - val_loss: 0.4889 - val_accuracy: 0.8061\n",
      "Epoch 9/15\n",
      "213/213 [==============================] - 6s 29ms/step - loss: 0.3285 - accuracy: 0.8726 - val_loss: 0.5738 - val_accuracy: 0.7626\n",
      "Epoch 10/15\n",
      "213/213 [==============================] - 6s 26ms/step - loss: 0.3277 - accuracy: 0.8715 - val_loss: 0.5077 - val_accuracy: 0.8090\n",
      "Epoch 11/15\n",
      "213/213 [==============================] - 6s 29ms/step - loss: 0.2528 - accuracy: 0.9038 - val_loss: 0.6604 - val_accuracy: 0.7885\n",
      "Epoch 12/15\n",
      "213/213 [==============================] - 6s 27ms/step - loss: 0.2442 - accuracy: 0.9064 - val_loss: 0.5390 - val_accuracy: 0.8137\n",
      "Epoch 13/15\n",
      "213/213 [==============================] - 6s 30ms/step - loss: 0.2211 - accuracy: 0.9129 - val_loss: 0.6136 - val_accuracy: 0.8255\n",
      "Epoch 14/15\n",
      "213/213 [==============================] - 6s 28ms/step - loss: 0.2053 - accuracy: 0.9229 - val_loss: 0.6028 - val_accuracy: 0.8196\n",
      "Epoch 15/15\n",
      "213/213 [==============================] - 6s 27ms/step - loss: 0.1404 - accuracy: 0.9479 - val_loss: 0.6170 - val_accuracy: 0.8196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9c2e1a09d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_subclass_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    # First convo-pooling\n",
    "    # Convolutional layers (filter the image with a kernel)\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", input_shape=[27, 27, 3]))\n",
    "    # Max-pooling layers (reduce the size of the image by choosing max pixel at certain area)\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    # Flatten input\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(3, activation=\"softmax\"))\n",
    "    # Compile model \n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_transfer_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    # Flatten input\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    # Hidden layers\n",
    "    model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=\"softmax\"))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(3, activation=\"sigmoid\"))\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(4, activation=\"softmax\"))\n",
    "    # Compile model\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "sub_multiclass = [\"epithelial\", \"fibroblast\", \"inflammatory\"]\n",
    "\n",
    "# imgs with 3 classes\n",
    "subcell_img, subcelltype_label = celltype_classify_data(sub_multiclass, root=\"Image_classification_data/multi-task\")\n",
    "subx_train, subx_test, suby_train, suby_test = train_test_split(\n",
    "    np.array(subcell_img), np.array(subcelltype_label), test_size=0.2\n",
    ")\n",
    "\n",
    "print(\"---Subclass training---\")\n",
    "# train subclass that fit with 3 types of images\n",
    "subclass_model = get_subclass_model()\n",
    "subclass_model.fit(subx_train, suby_train, epochs=15, validation_data=(subx_test, suby_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c669d9",
   "metadata": {},
   "source": [
    "### Multiclass + ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "76680b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Second model (4 classes model) training---\n",
      "Epoch 1/100\n",
      "  1/248 [..............................] - ETA: 1:14 - loss: 1.3386 - accuracy: 0.4688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 10:41:10.093982: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248/248 [==============================] - ETA: 0s - loss: 1.1876 - accuracy: 0.4889"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 10:41:11.898375: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248/248 [==============================] - 2s 8ms/step - loss: 1.1876 - accuracy: 0.4889 - val_loss: 0.9993 - val_accuracy: 0.5742\n",
      "Epoch 2/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.8610 - accuracy: 0.8084 - val_loss: 0.7887 - val_accuracy: 0.8157\n",
      "Epoch 3/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.7288 - accuracy: 0.8240 - val_loss: 0.7102 - val_accuracy: 0.8152\n",
      "Epoch 4/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.6737 - accuracy: 0.8239 - val_loss: 0.6672 - val_accuracy: 0.8167\n",
      "Epoch 5/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.6402 - accuracy: 0.8235 - val_loss: 0.6393 - val_accuracy: 0.8152\n",
      "Epoch 6/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.6182 - accuracy: 0.8239 - val_loss: 0.6166 - val_accuracy: 0.8162\n",
      "Epoch 7/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.6012 - accuracy: 0.8239 - val_loss: 0.6005 - val_accuracy: 0.8167\n",
      "Epoch 8/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5895 - accuracy: 0.8224 - val_loss: 0.5907 - val_accuracy: 0.8141\n",
      "Epoch 9/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5732 - accuracy: 0.8231 - val_loss: 0.5735 - val_accuracy: 0.8162\n",
      "Epoch 10/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5603 - accuracy: 0.8266 - val_loss: 0.5647 - val_accuracy: 0.8157\n",
      "Epoch 11/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5515 - accuracy: 0.8276 - val_loss: 0.5522 - val_accuracy: 0.8187\n",
      "Epoch 12/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5433 - accuracy: 0.8293 - val_loss: 0.5450 - val_accuracy: 0.8187\n",
      "Epoch 13/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5376 - accuracy: 0.8298 - val_loss: 0.5367 - val_accuracy: 0.8197\n",
      "Epoch 14/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5335 - accuracy: 0.8296 - val_loss: 0.5340 - val_accuracy: 0.8263\n",
      "Epoch 15/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5276 - accuracy: 0.8307 - val_loss: 0.5315 - val_accuracy: 0.8263\n",
      "Epoch 16/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5240 - accuracy: 0.8308 - val_loss: 0.5296 - val_accuracy: 0.8268\n",
      "Epoch 17/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5198 - accuracy: 0.8316 - val_loss: 0.5257 - val_accuracy: 0.8283\n",
      "Epoch 18/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5189 - accuracy: 0.8317 - val_loss: 0.5245 - val_accuracy: 0.8288\n",
      "Epoch 19/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5149 - accuracy: 0.8327 - val_loss: 0.5184 - val_accuracy: 0.8273\n",
      "Epoch 20/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5139 - accuracy: 0.8324 - val_loss: 0.5177 - val_accuracy: 0.8278\n",
      "Epoch 21/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5118 - accuracy: 0.8334 - val_loss: 0.5210 - val_accuracy: 0.8278\n",
      "Epoch 22/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5109 - accuracy: 0.8341 - val_loss: 0.5146 - val_accuracy: 0.8308\n",
      "Epoch 23/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5092 - accuracy: 0.8335 - val_loss: 0.5177 - val_accuracy: 0.8288\n",
      "Epoch 24/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5089 - accuracy: 0.8330 - val_loss: 0.5100 - val_accuracy: 0.8308\n",
      "Epoch 25/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5078 - accuracy: 0.8339 - val_loss: 0.5114 - val_accuracy: 0.8308\n",
      "Epoch 26/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5074 - accuracy: 0.8334 - val_loss: 0.5118 - val_accuracy: 0.8308\n",
      "Epoch 27/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5071 - accuracy: 0.8339 - val_loss: 0.5136 - val_accuracy: 0.8273\n",
      "Epoch 28/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5059 - accuracy: 0.8340 - val_loss: 0.5098 - val_accuracy: 0.8318\n",
      "Epoch 29/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5078 - accuracy: 0.8349 - val_loss: 0.5116 - val_accuracy: 0.8298\n",
      "Epoch 30/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5057 - accuracy: 0.8356 - val_loss: 0.5121 - val_accuracy: 0.8247\n",
      "Epoch 31/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5056 - accuracy: 0.8345 - val_loss: 0.5106 - val_accuracy: 0.8308\n",
      "Epoch 32/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5048 - accuracy: 0.8354 - val_loss: 0.5053 - val_accuracy: 0.8348\n",
      "Epoch 33/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5048 - accuracy: 0.8350 - val_loss: 0.5090 - val_accuracy: 0.8298\n",
      "Epoch 34/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5043 - accuracy: 0.8362 - val_loss: 0.5064 - val_accuracy: 0.8303\n",
      "Epoch 35/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5040 - accuracy: 0.8355 - val_loss: 0.5065 - val_accuracy: 0.8258\n",
      "Epoch 36/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5048 - accuracy: 0.8350 - val_loss: 0.5084 - val_accuracy: 0.8303\n",
      "Epoch 37/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5045 - accuracy: 0.8362 - val_loss: 0.5071 - val_accuracy: 0.8273\n",
      "Epoch 38/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5048 - accuracy: 0.8354 - val_loss: 0.5083 - val_accuracy: 0.8343\n",
      "Epoch 39/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5044 - accuracy: 0.8353 - val_loss: 0.5038 - val_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5022 - accuracy: 0.8356 - val_loss: 0.5084 - val_accuracy: 0.8303\n",
      "Epoch 41/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5037 - accuracy: 0.8346 - val_loss: 0.5073 - val_accuracy: 0.8313\n",
      "Epoch 42/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5014 - accuracy: 0.8358 - val_loss: 0.5074 - val_accuracy: 0.8343\n",
      "Epoch 43/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5025 - accuracy: 0.8353 - val_loss: 0.5040 - val_accuracy: 0.8318\n",
      "Epoch 44/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5032 - accuracy: 0.8365 - val_loss: 0.5056 - val_accuracy: 0.8328\n",
      "Epoch 45/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5017 - accuracy: 0.8369 - val_loss: 0.5096 - val_accuracy: 0.8328\n",
      "Epoch 46/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5024 - accuracy: 0.8362 - val_loss: 0.5131 - val_accuracy: 0.8313\n",
      "Epoch 47/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5017 - accuracy: 0.8369 - val_loss: 0.5104 - val_accuracy: 0.8313\n",
      "Epoch 48/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5020 - accuracy: 0.8368 - val_loss: 0.5058 - val_accuracy: 0.8328\n",
      "Epoch 49/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5013 - accuracy: 0.8362 - val_loss: 0.5060 - val_accuracy: 0.8338\n",
      "Epoch 50/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5019 - accuracy: 0.8373 - val_loss: 0.5044 - val_accuracy: 0.8354\n",
      "Epoch 51/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5021 - accuracy: 0.8363 - val_loss: 0.5039 - val_accuracy: 0.8328\n",
      "Epoch 52/100\n",
      "248/248 [==============================] - 2s 8ms/step - loss: 0.5018 - accuracy: 0.8362 - val_loss: 0.5075 - val_accuracy: 0.8328\n",
      "Epoch 53/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5013 - accuracy: 0.8355 - val_loss: 0.5055 - val_accuracy: 0.8338\n",
      "Epoch 54/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5012 - accuracy: 0.8362 - val_loss: 0.5028 - val_accuracy: 0.8338\n",
      "Epoch 55/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5018 - accuracy: 0.8374 - val_loss: 0.5063 - val_accuracy: 0.8338\n",
      "Epoch 56/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5014 - accuracy: 0.8368 - val_loss: 0.5015 - val_accuracy: 0.8354\n",
      "Epoch 57/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5013 - accuracy: 0.8362 - val_loss: 0.5075 - val_accuracy: 0.8338\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5009 - accuracy: 0.8363 - val_loss: 0.5064 - val_accuracy: 0.8348\n",
      "Epoch 59/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5027 - accuracy: 0.8368 - val_loss: 0.5042 - val_accuracy: 0.8338\n",
      "Epoch 60/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5014 - accuracy: 0.8378 - val_loss: 0.5062 - val_accuracy: 0.8338\n",
      "Epoch 61/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5003 - accuracy: 0.8374 - val_loss: 0.5030 - val_accuracy: 0.8343\n",
      "Epoch 62/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5001 - accuracy: 0.8375 - val_loss: 0.5058 - val_accuracy: 0.8354\n",
      "Epoch 63/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5007 - accuracy: 0.8368 - val_loss: 0.5048 - val_accuracy: 0.8343\n",
      "Epoch 64/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5018 - accuracy: 0.8372 - val_loss: 0.5052 - val_accuracy: 0.8338\n",
      "Epoch 65/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5006 - accuracy: 0.8362 - val_loss: 0.5034 - val_accuracy: 0.8348\n",
      "Epoch 66/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5010 - accuracy: 0.8380 - val_loss: 0.5007 - val_accuracy: 0.8343\n",
      "Epoch 67/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5030 - accuracy: 0.8358 - val_loss: 0.5062 - val_accuracy: 0.8333\n",
      "Epoch 68/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5007 - accuracy: 0.8363 - val_loss: 0.5070 - val_accuracy: 0.8343\n",
      "Epoch 69/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5007 - accuracy: 0.8364 - val_loss: 0.5072 - val_accuracy: 0.8343\n",
      "Epoch 70/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5007 - accuracy: 0.8358 - val_loss: 0.5025 - val_accuracy: 0.8348\n",
      "Epoch 71/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5004 - accuracy: 0.8373 - val_loss: 0.5028 - val_accuracy: 0.8343\n",
      "Epoch 72/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5002 - accuracy: 0.8365 - val_loss: 0.5049 - val_accuracy: 0.8343\n",
      "Epoch 73/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5002 - accuracy: 0.8359 - val_loss: 0.5046 - val_accuracy: 0.8359\n",
      "Epoch 74/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.4997 - accuracy: 0.8380 - val_loss: 0.5026 - val_accuracy: 0.8338\n",
      "Epoch 75/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5009 - accuracy: 0.8373 - val_loss: 0.5071 - val_accuracy: 0.8348\n",
      "Epoch 76/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5005 - accuracy: 0.8372 - val_loss: 0.5065 - val_accuracy: 0.8343\n",
      "Epoch 77/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5007 - accuracy: 0.8373 - val_loss: 0.5029 - val_accuracy: 0.8354\n",
      "Epoch 78/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.4995 - accuracy: 0.8377 - val_loss: 0.5057 - val_accuracy: 0.8333\n",
      "Epoch 79/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.4994 - accuracy: 0.8375 - val_loss: 0.5072 - val_accuracy: 0.8333\n",
      "Epoch 80/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.4999 - accuracy: 0.8370 - val_loss: 0.5026 - val_accuracy: 0.8359\n",
      "Epoch 81/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5008 - accuracy: 0.8378 - val_loss: 0.5077 - val_accuracy: 0.8338\n",
      "Epoch 82/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5007 - accuracy: 0.8368 - val_loss: 0.5001 - val_accuracy: 0.8338\n",
      "Epoch 83/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5002 - accuracy: 0.8370 - val_loss: 0.5062 - val_accuracy: 0.8333\n",
      "Epoch 84/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5005 - accuracy: 0.8358 - val_loss: 0.5012 - val_accuracy: 0.8338\n",
      "Epoch 85/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5003 - accuracy: 0.8377 - val_loss: 0.5033 - val_accuracy: 0.8343\n",
      "Epoch 86/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5000 - accuracy: 0.8362 - val_loss: 0.5040 - val_accuracy: 0.8343\n",
      "Epoch 87/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.4994 - accuracy: 0.8369 - val_loss: 0.5035 - val_accuracy: 0.8348\n",
      "Epoch 88/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.4997 - accuracy: 0.8380 - val_loss: 0.5034 - val_accuracy: 0.8333\n",
      "Epoch 89/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.4997 - accuracy: 0.8367 - val_loss: 0.5041 - val_accuracy: 0.8338\n",
      "Epoch 90/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.4988 - accuracy: 0.8368 - val_loss: 0.5062 - val_accuracy: 0.8343\n",
      "Epoch 91/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.4990 - accuracy: 0.8365 - val_loss: 0.5044 - val_accuracy: 0.8348\n",
      "Epoch 92/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.4989 - accuracy: 0.8369 - val_loss: 0.5046 - val_accuracy: 0.8348\n",
      "Epoch 93/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.4995 - accuracy: 0.8374 - val_loss: 0.5044 - val_accuracy: 0.8343\n",
      "Epoch 94/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.4991 - accuracy: 0.8362 - val_loss: 0.5046 - val_accuracy: 0.8338\n",
      "Epoch 95/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.4994 - accuracy: 0.8369 - val_loss: 0.5056 - val_accuracy: 0.8348\n",
      "Epoch 96/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.5000 - accuracy: 0.8367 - val_loss: 0.5035 - val_accuracy: 0.8343\n",
      "Epoch 97/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.4981 - accuracy: 0.8370 - val_loss: 0.5011 - val_accuracy: 0.8348\n",
      "Epoch 98/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.4995 - accuracy: 0.8373 - val_loss: 0.5026 - val_accuracy: 0.8348\n",
      "Epoch 99/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.4988 - accuracy: 0.8370 - val_loss: 0.5053 - val_accuracy: 0.8343\n",
      "Epoch 100/100\n",
      "248/248 [==============================] - 2s 7ms/step - loss: 0.4997 - accuracy: 0.8364 - val_loss: 0.5042 - val_accuracy: 0.8338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d7403c10>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_class = [\"epithelial\", \"fibroblast\", \"inflammatory\", \"others\"]\n",
    "# imgs with 4 classes\n",
    "cell_img, celltype_label = celltype_classify_data(all_class)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    np.array(cell_img), np.array(celltype_label), test_size=0.2\n",
    ")\n",
    "\n",
    "# get transfered model and train with 4 types of images\n",
    "transfer_x_train = subclass_model.predict(x_train)\n",
    "transfer_x_test = subclass_model.predict(x_test)\n",
    "transfer_model = get_transfer_model()\n",
    "\n",
    "print(\"---Second model (4 classes model) training---\")\n",
    "transfer_model.fit(transfer_x_train, y_train, epochs=40, validation_data=(transfer_x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7750be6d",
   "metadata": {},
   "source": [
    "### Stacked output from 3 classes and 4 models as meta-learner x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49bdfc0",
   "metadata": {},
   "source": [
    "### Nilvng attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b9595b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 18:01:19.942307: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f9c47453290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f9c47453290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "248/248 [==============================] - ETA: 0s - loss: 1.0548 - accuracy: 0.5648WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f9c4f26e200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f9c4f26e200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "248/248 [==============================] - 33s 127ms/step - loss: 1.0548 - accuracy: 0.5648 - val_loss: 0.8912 - val_accuracy: 0.6384\n",
      "Epoch 2/15\n",
      "248/248 [==============================] - 29s 116ms/step - loss: 0.8173 - accuracy: 0.6785 - val_loss: 0.7538 - val_accuracy: 0.6924\n",
      "Epoch 3/15\n",
      "248/248 [==============================] - 30s 119ms/step - loss: 0.7425 - accuracy: 0.7091 - val_loss: 0.8015 - val_accuracy: 0.6934\n",
      "Epoch 4/15\n",
      "248/248 [==============================] - 29s 116ms/step - loss: 0.7080 - accuracy: 0.7252 - val_loss: 0.7663 - val_accuracy: 0.6828\n",
      "Epoch 5/15\n",
      "248/248 [==============================] - 33s 131ms/step - loss: 0.6792 - accuracy: 0.7394 - val_loss: 0.6457 - val_accuracy: 0.7475\n",
      "Epoch 6/15\n",
      "248/248 [==============================] - 33s 135ms/step - loss: 0.6510 - accuracy: 0.7510 - val_loss: 0.6580 - val_accuracy: 0.7359\n",
      "Epoch 7/15\n",
      "248/248 [==============================] - 199s 803ms/step - loss: 0.6251 - accuracy: 0.7612 - val_loss: 0.6655 - val_accuracy: 0.7313\n",
      "Epoch 8/15\n",
      "248/248 [==============================] - 35s 140ms/step - loss: 0.6020 - accuracy: 0.7722 - val_loss: 0.7339 - val_accuracy: 0.7212\n",
      "Epoch 9/15\n",
      "248/248 [==============================] - 30s 121ms/step - loss: 0.5488 - accuracy: 0.7882 - val_loss: 0.6920 - val_accuracy: 0.7495\n",
      "Epoch 10/15\n",
      "248/248 [==============================] - 29s 117ms/step - loss: 0.5068 - accuracy: 0.8036 - val_loss: 0.7322 - val_accuracy: 0.7354\n",
      "Epoch 11/15\n",
      "248/248 [==============================] - 31s 126ms/step - loss: 0.4640 - accuracy: 0.8278 - val_loss: 0.7843 - val_accuracy: 0.7338\n",
      "Epoch 12/15\n",
      "248/248 [==============================] - 33s 134ms/step - loss: 0.4008 - accuracy: 0.8517 - val_loss: 0.7748 - val_accuracy: 0.7434\n",
      "Epoch 13/15\n",
      "248/248 [==============================] - 32s 128ms/step - loss: 0.3434 - accuracy: 0.8753 - val_loss: 0.8267 - val_accuracy: 0.7369\n",
      "Epoch 14/15\n",
      "248/248 [==============================] - 31s 127ms/step - loss: 0.3091 - accuracy: 0.8892 - val_loss: 0.9022 - val_accuracy: 0.7298\n",
      "Epoch 15/15\n",
      "248/248 [==============================] - 29s 115ms/step - loss: 0.2463 - accuracy: 0.9092 - val_loss: 1.0542 - val_accuracy: 0.7232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9c8bb82c50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = \"Image_classification_data/multi-task\"\n",
    "cell_img, celltype_label = celltype_classify_data(all_class, root=root)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    np.array(cell_img), np.array(celltype_label), test_size=0.2\n",
    ")\n",
    "\n",
    "model = get_multiclass_model()\n",
    "\n",
    "model.fit(x_train, y_train, epochs=15, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67e93dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f9c6d033440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f9c6d033440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f9c6de7d050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f9c6de7d050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f9c5748f710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f9c5748f710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "245/248 [============================>.] - ETA: 0s - loss: 1.1795 - accuracy: 0.4304WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f9c6de9bdd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f9c6de9bdd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 1.1778 - accuracy: 0.4323 - val_loss: 0.9621 - val_accuracy: 0.6394\n",
      "Epoch 2/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.8603 - accuracy: 0.7434 - val_loss: 0.7843 - val_accuracy: 0.7985\n",
      "Epoch 3/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.7272 - accuracy: 0.8477 - val_loss: 0.6902 - val_accuracy: 0.8990\n",
      "Epoch 4/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.6437 - accuracy: 0.9117 - val_loss: 0.6221 - val_accuracy: 0.8975\n",
      "Epoch 5/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.5831 - accuracy: 0.9112 - val_loss: 0.5627 - val_accuracy: 0.9086\n",
      "Epoch 6/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.9112 - val_loss: 0.5197 - val_accuracy: 0.9111\n",
      "Epoch 7/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.5018 - accuracy: 0.9104 - val_loss: 0.5022 - val_accuracy: 0.9025\n",
      "Epoch 8/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.4723 - accuracy: 0.9117 - val_loss: 0.4736 - val_accuracy: 0.9015\n",
      "Epoch 9/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.4473 - accuracy: 0.9133 - val_loss: 0.4452 - val_accuracy: 0.9020\n",
      "Epoch 10/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.4276 - accuracy: 0.9118 - val_loss: 0.4252 - val_accuracy: 0.9051\n",
      "Epoch 11/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.4118 - accuracy: 0.9097 - val_loss: 0.4104 - val_accuracy: 0.9035\n",
      "Epoch 12/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.3941 - accuracy: 0.9146 - val_loss: 0.3918 - val_accuracy: 0.9066\n",
      "Epoch 13/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.3744 - accuracy: 0.9142 - val_loss: 0.3805 - val_accuracy: 0.9066\n",
      "Epoch 14/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.3593 - accuracy: 0.9141 - val_loss: 0.3691 - val_accuracy: 0.9061\n",
      "Epoch 15/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.3475 - accuracy: 0.9136 - val_loss: 0.3594 - val_accuracy: 0.9030\n",
      "Epoch 16/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.3380 - accuracy: 0.9150 - val_loss: 0.3459 - val_accuracy: 0.9111\n",
      "Epoch 17/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.3296 - accuracy: 0.9140 - val_loss: 0.3397 - val_accuracy: 0.9121\n",
      "Epoch 18/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.3209 - accuracy: 0.9137 - val_loss: 0.3311 - val_accuracy: 0.9071\n",
      "Epoch 19/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.3160 - accuracy: 0.9140 - val_loss: 0.3246 - val_accuracy: 0.9121\n",
      "Epoch 20/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.3089 - accuracy: 0.9127 - val_loss: 0.3272 - val_accuracy: 0.9091\n",
      "Epoch 21/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.3039 - accuracy: 0.9142 - val_loss: 0.3184 - val_accuracy: 0.9116\n",
      "Epoch 22/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.2996 - accuracy: 0.9151 - val_loss: 0.3114 - val_accuracy: 0.9111\n",
      "Epoch 23/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.2938 - accuracy: 0.9150 - val_loss: 0.3153 - val_accuracy: 0.9045\n",
      "Epoch 24/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.2909 - accuracy: 0.9137 - val_loss: 0.3046 - val_accuracy: 0.9111\n",
      "Epoch 25/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.2871 - accuracy: 0.9142 - val_loss: 0.3017 - val_accuracy: 0.9081\n",
      "Epoch 26/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.2838 - accuracy: 0.9160 - val_loss: 0.2991 - val_accuracy: 0.9061\n",
      "Epoch 27/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.2816 - accuracy: 0.9155 - val_loss: 0.3014 - val_accuracy: 0.9056\n",
      "Epoch 28/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.2793 - accuracy: 0.9133 - val_loss: 0.3029 - val_accuracy: 0.9051\n",
      "Epoch 29/30\n",
      "248/248 [==============================] - 1s 4ms/step - loss: 0.2781 - accuracy: 0.9142 - val_loss: 0.2942 - val_accuracy: 0.9101\n",
      "Epoch 30/30\n",
      "248/248 [==============================] - 1s 5ms/step - loss: 0.2753 - accuracy: 0.9150 - val_loss: 0.2959 - val_accuracy: 0.9106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9c6dec7dd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imgs with 3 classes\n",
    "subcell_img, subcelltype_label = celltype_classify_data(sub_multiclass, root=\"Image_classification_data/multi-task\")\n",
    "subx_train, subx_test, suby_train, suby_test = train_test_split(\n",
    "    np.array(subcell_img), np.array(subcelltype_label), test_size=0.2\n",
    ")\n",
    "\n",
    "# imgs with 4 classes\n",
    "cell_img, celltype_label = celltype_classify_data(all_class, root=\"Image_classification_data/multi-task\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    np.array(cell_img), np.array(celltype_label), test_size=0.2\n",
    ")\n",
    "\n",
    "# get transfered model (3 classes model) and predict with 4 types of images\n",
    "transfer_x_train = subclass_model.predict(x_train)\n",
    "transfer_x_test = subclass_model.predict(x_test)\n",
    "\n",
    "# get base model (4 classes model) and predict to get another x\n",
    "base_x = model.predict(x_train)\n",
    "base_x_test = model.predict(x_test)\n",
    "\n",
    "stacked_x_train = np.concatenate((transfer_x_train, base_x), axis=1)\n",
    "stack_x_test = np.concatenate((transfer_x_test, base_x_test), axis=1)\n",
    "\n",
    "transfer_model = get_transfer_model()\n",
    "transfer_model.fit(stacked_x_train, y_train, epochs=30, validation_data=(stack_x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "625387cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7916, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfer_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "926dc650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.114601</td>\n",
       "      <td>0.012736</td>\n",
       "      <td>8.726634e-01</td>\n",
       "      <td>0.075905</td>\n",
       "      <td>0.033890</td>\n",
       "      <td>8.712006e-01</td>\n",
       "      <td>0.019005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999552</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>7.318934e-07</td>\n",
       "      <td>0.989972</td>\n",
       "      <td>0.010012</td>\n",
       "      <td>5.260985e-07</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.972770</td>\n",
       "      <td>0.024776</td>\n",
       "      <td>2.454151e-03</td>\n",
       "      <td>0.738803</td>\n",
       "      <td>0.256790</td>\n",
       "      <td>5.303503e-05</td>\n",
       "      <td>0.004354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009097</td>\n",
       "      <td>0.803798</td>\n",
       "      <td>1.871049e-01</td>\n",
       "      <td>0.018818</td>\n",
       "      <td>0.972337</td>\n",
       "      <td>8.014997e-03</td>\n",
       "      <td>0.000831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.070732</td>\n",
       "      <td>0.011505</td>\n",
       "      <td>9.177624e-01</td>\n",
       "      <td>0.009966</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>9.881272e-01</td>\n",
       "      <td>0.001767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7911</th>\n",
       "      <td>0.011466</td>\n",
       "      <td>0.888609</td>\n",
       "      <td>9.992539e-02</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>0.437562</td>\n",
       "      <td>5.011983e-01</td>\n",
       "      <td>0.059449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7912</th>\n",
       "      <td>0.008633</td>\n",
       "      <td>0.007608</td>\n",
       "      <td>9.837596e-01</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.005248</td>\n",
       "      <td>9.898542e-01</td>\n",
       "      <td>0.003810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7913</th>\n",
       "      <td>0.878431</td>\n",
       "      <td>0.074332</td>\n",
       "      <td>4.723708e-02</td>\n",
       "      <td>0.899661</td>\n",
       "      <td>0.074821</td>\n",
       "      <td>6.451719e-03</td>\n",
       "      <td>0.019067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7914</th>\n",
       "      <td>0.050066</td>\n",
       "      <td>0.937349</td>\n",
       "      <td>1.258421e-02</td>\n",
       "      <td>0.005891</td>\n",
       "      <td>0.958345</td>\n",
       "      <td>5.871809e-03</td>\n",
       "      <td>0.029892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7915</th>\n",
       "      <td>0.019566</td>\n",
       "      <td>0.026134</td>\n",
       "      <td>9.543000e-01</td>\n",
       "      <td>0.008785</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>9.868390e-01</td>\n",
       "      <td>0.003235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7916 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1             2         3         4             5  \\\n",
       "0     0.114601  0.012736  8.726634e-01  0.075905  0.033890  8.712006e-01   \n",
       "1     0.999552  0.000447  7.318934e-07  0.989972  0.010012  5.260985e-07   \n",
       "2     0.972770  0.024776  2.454151e-03  0.738803  0.256790  5.303503e-05   \n",
       "3     0.009097  0.803798  1.871049e-01  0.018818  0.972337  8.014997e-03   \n",
       "4     0.070732  0.011505  9.177624e-01  0.009966  0.000139  9.881272e-01   \n",
       "...        ...       ...           ...       ...       ...           ...   \n",
       "7911  0.011466  0.888609  9.992539e-02  0.001791  0.437562  5.011983e-01   \n",
       "7912  0.008633  0.007608  9.837596e-01  0.001089  0.005248  9.898542e-01   \n",
       "7913  0.878431  0.074332  4.723708e-02  0.899661  0.074821  6.451719e-03   \n",
       "7914  0.050066  0.937349  1.258421e-02  0.005891  0.958345  5.871809e-03   \n",
       "7915  0.019566  0.026134  9.543000e-01  0.008785  0.001142  9.868390e-01   \n",
       "\n",
       "             6  \n",
       "0     0.019005  \n",
       "1     0.000016  \n",
       "2     0.004354  \n",
       "3     0.000831  \n",
       "4     0.001767  \n",
       "...        ...  \n",
       "7911  0.059449  \n",
       "7912  0.003810  \n",
       "7913  0.019067  \n",
       "7914  0.029892  \n",
       "7915  0.003235  \n",
       "\n",
       "[7916 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(stacked_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8155f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f9c6d0337a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f9c6d0337a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95       834\n",
      "           1       0.90      0.89      0.89       359\n",
      "           2       0.88      0.91      0.90       490\n",
      "           3       0.89      0.77      0.83       297\n",
      "\n",
      "    accuracy                           0.91      1980\n",
      "   macro avg       0.90      0.88      0.89      1980\n",
      "weighted avg       0.91      0.91      0.91      1980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transfer_pred = transfer_model.predict(stack_x_test)\n",
    "\n",
    "encoded_pred = list()\n",
    "for pred in transfer_pred:\n",
    "    encoded_pred.append(np.argmax(pred))\n",
    "    \n",
    "encoded_pred = np.array(encoded_pred)\n",
    "print(classification_report(y_test, encoded_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ef5cc1",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f0a27724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data in class 0 in data 4079\n",
      "No data in class 1 in data 1888\n",
      "No data in class 2 in data 2543\n",
      "No data in class 3 in data 1386\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(f\"No data in class {i} in data\", (np.array(celltype_label)==i).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848b3774",
   "metadata": {},
   "source": [
    "### Multiclass + Oversampling + Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4bb6d4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data in class 0 in oversampled data 4079\n",
      "No data in class 1 in oversampled data 4079\n",
      "No data in class 2 in oversampled data 4079\n",
      "No data in class 3 in oversampled data 4079\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       811\n",
      "           1       0.74      0.88      0.80       789\n",
      "           2       0.75      0.86      0.80       822\n",
      "           3       0.67      0.43      0.52       842\n",
      "\n",
      "    accuracy                           0.76      3264\n",
      "   macro avg       0.75      0.77      0.75      3264\n",
      "weighted avg       0.75      0.76      0.75      3264\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91       811\n",
      "           1       0.75      0.92      0.83       789\n",
      "           2       0.76      0.89      0.82       822\n",
      "           3       0.76      0.43      0.54       842\n",
      "\n",
      "    accuracy                           0.79      3264\n",
      "   macro avg       0.79      0.79      0.78      3264\n",
      "weighted avg       0.79      0.79      0.77      3264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "cell_img, celltype_label = celltype_classify_data(all_class)\n",
    "transfered_x = subclass_model.predict(np.array(cell_img))\n",
    "\n",
    "# by default, it would only over sample minority class which is the aim in this case\n",
    "oversample = SMOTE()\n",
    "transfered_x, celltype_label = oversample.fit_resample(transfered_x, np.array(celltype_label))\n",
    "\n",
    "for i in range(4):\n",
    "    print(f\"No data in class {i} in oversampled data\", (np.array(celltype_label)==i).sum())\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    transfered_x, celltype_label, test_size=0.2\n",
    ")\n",
    "\n",
    "tree_classifier = tree.DecisionTreeClassifier(class_weight=\"balanced\")\n",
    "tree_classifier = tree_classifier.fit(x_train, y_train)\n",
    "\n",
    "forest_classifier = RandomForestClassifier(class_weight=\"balanced\")\n",
    "forest_classifier.fit(x_train, y_train)\n",
    "\n",
    "tree_pred = tree_classifier.predict(x_test)\n",
    "forest_pred = forest_classifier.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, tree_pred))\n",
    "print(classification_report(y_test, forest_pred))                                        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f85430522e24dcceb49f547c8042b2746187a0750be8e55b7097447c175006b"
  },
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
