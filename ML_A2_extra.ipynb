{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19ac42e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_tuner as kt\n",
    "from sklearn.metrics import classification_report\n",
    "import shutil\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# path variables to access files\n",
    "root = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7434e2ba",
   "metadata": {},
   "source": [
    "### Load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff2688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = pd.read_csv(\"data_labels_mainData.csv\")\n",
    "extra_data = pd.read_csv(\"data_labels_extraData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8b54b5",
   "metadata": {},
   "source": [
    "### Get data from splitted folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63c61732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method get data for multiclass task (task 2)\n",
    "def celltype_classify_data(class_list):    \n",
    "    images = list()\n",
    "    labels = list()\n",
    "    \n",
    "    for i, label in enumerate(class_list):\n",
    "        # get image directory\n",
    "        img_dir = os.path.join(root, \"multiclass_task\", f\"{label}\")\n",
    "        \n",
    "        for img in os.listdir(img_dir):\n",
    "            img = cv2.imread(os.path.join(img_dir, img))\n",
    "            # resize to 0-1 for faster computation\n",
    "            resized = img / 255\n",
    "            images.append(resized)\n",
    "            labels.append(i)\n",
    "        \n",
    "    return (images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d50611",
   "metadata": {},
   "source": [
    "### Classification report method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6644e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_classification_report(y_test, prediction):\n",
    "    \"\"\"\n",
    "        Method to generate sklearn classification report with CNN multiclass output\n",
    "    \"\"\"\n",
    "    \n",
    "    encoded_pred = list()\n",
    "    # convert each CNN output (sparse categorial) to class\n",
    "    for pred in prediction:\n",
    "        encoded_pred.append(np.argmax(pred))\n",
    "\n",
    "    encoded_pred = np.array(encoded_pred)\n",
    "    print(classification_report(y_test, encoded_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c1e833",
   "metadata": {},
   "source": [
    "### Structure of sub-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cf0ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiclass_model():\n",
    "    \"\"\"\n",
    "        Structure of model classifying 4 classes\n",
    "    \"\"\"\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    # First convo-pooling\n",
    "    # Convolutional layers (filter the image with a kernel)\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), strides=1,activation=\"relu\", input_shape=[27, 27, 3]))\n",
    "    # Max-pooling layers (reduce the size of the image by choosing max pixel at certain area)\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=1))\n",
    "    \n",
    "    # Second convo-pooling\n",
    "    # Convolutional layers (filter the image with a kernel)\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3),strides=1, activation=\"relu\"))\n",
    "    # Max-pooling layers (reduce the size of the image by choosing max pixel at certain area)\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2),strides=1))\n",
    "    \n",
    "    # Flatten input\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(2, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(4, activation=\"softmax\"))\n",
    "    # Compile model \n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_subclass_model():\n",
    "    \"\"\"\n",
    "        Structure of model classifying 3 classes\n",
    "    \"\"\"\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    # First convo-pooling\n",
    "    # Convolutional layers (filter the image with a kernel)\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", input_shape=[27, 27, 3]))\n",
    "    # Max-pooling layers (reduce the size of the image by choosing max pixel at certain area)\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    # Flatten input\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(3, activation=\"softmax\"))\n",
    "    # Compile model \n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef69168",
   "metadata": {},
   "source": [
    "### Methods to train and save submodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9341569",
   "metadata": {},
   "outputs": [],
   "source": [
    "submodel_path = os.path.join(root, \"multiclass_submodels\")   \n",
    "def three_class_submodel(file_path, aug_train = None, aug_val = None):\n",
    "    # path to model trained with 3 classes\n",
    "    subclass_path = path.join(file_path, \"subclass.h5\")\n",
    "    subclass_model = None\n",
    "    if not os.path.isfile(subclass_path) or keras.models.load_model(subclass_path) == None:\n",
    "        print(\"---Sub model training---\")\n",
    "        # train subclass that fit with 3 types of images\n",
    "        subclass_model = get_subclass_model()\n",
    "        \n",
    "        if aug_train is not None and aug_val is not None:\n",
    "            print(\"Train with augmented data\")\n",
    "            subclass_model.fit(aug_train, epochs=40, validation_data=aug_val)\n",
    "        else:\n",
    "            print(\"Train with non-augmented data\")\n",
    "            subclass_model.fit(subx_train, suby_train, epochs=40, validation_data=(subx_test, suby_test))\n",
    "            \n",
    "        subclass_model.save(subclass_path)\n",
    "        return subclass_model\n",
    "    else:\n",
    "        subclass_model = keras.models.load_model(subclass_path)\n",
    "        print(\"Model trained with 3 classes loaded\")\n",
    "        return subclass_model\n",
    "    \n",
    "def all_class_submodel(file_path, aug_train = None, aug_val = None):\n",
    "    allclass_path = path.join(file_path, \"allclass.h5\")\n",
    "    allclass_model = None\n",
    "    if not os.path.isfile(allclass_path) or keras.models.load_model(allclass_path) == None:\n",
    "        print(\"---Sub model training---\")\n",
    "        # train subclass that fit with 4 types of images\n",
    "        allclass_model = get_multiclass_model()\n",
    "        \n",
    "        if aug_train is not None and aug_val is not None:\n",
    "            print(\"Train with augmented data\")\n",
    "            allclass_model.fit(aug_train, epochs=15, validation_data=aug_val)\n",
    "        else:\n",
    "            print(\"Train with non-augmented data\")\n",
    "            allclass_model.fit(x_train, y_train, epochs=15, validation_data=(x_val, y_val))\n",
    "            \n",
    "        allclass_model.save(allclass_path)\n",
    "        return allclass_model\n",
    "    else:\n",
    "        allclass_model = keras.models.load_model(allclass_path)\n",
    "        print(\"Model trained with 4 classes loaded\")\n",
    "        return allclass_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c40b39",
   "metadata": {},
   "source": [
    "### Meta-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13a29b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transfer_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    # Flatten input\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    # Hidden layers\n",
    "    model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=\"softmax\"))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(3, activation=\"sigmoid\"))\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(4, activation=\"softmax\"))\n",
    "    # Compile model\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4c3911",
   "metadata": {},
   "source": [
    "### Get augmentated data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d672cb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images from folders\n",
    "all_class = [\"epithelial\", \"fibroblast\", \"inflammatory\", \"others\"]\n",
    "cell_img, cell_label = celltype_classify_data(all_class)\n",
    "cell_img, cell_label = np.array(cell_img), np.array(cell_label)\n",
    "\n",
    "sub_multiclass = [\"epithelial\", \"fibroblast\", \"inflammatory\"]\n",
    "sub_img, sub_label = celltype_classify_data(sub_multiclass)\n",
    "\n",
    "# train and validate data for 3 classes\n",
    "subx_train, subx_test, suby_train, suby_test = train_test_split(\n",
    "    np.array(sub_img), np.array(sub_label), test_size=0.2\n",
    ")\n",
    "\n",
    "# train and validate data for 4 classes\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(\n",
    "    cell_img, cell_label, test_size=0.2\n",
    ")\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train_val, y_train_val, test_size=0.25\n",
    ")\n",
    "\n",
    "# get augmentation for extra training data\n",
    "extra_datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    rotation_range=60,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "\n",
    ")\n",
    "\n",
    "# fit augmentation with all images from all 4 classes\n",
    "extra_datagen.fit(cell_img)\n",
    "\n",
    "# get augmentations for unlabeled data\n",
    "shift_aug = ImageDataGenerator(\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    ")\n",
    "rotation_aug = ImageDataGenerator(\n",
    "    rotation_range=60\n",
    ")\n",
    "flip_aug = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    ")\n",
    "aug_list = [shift_aug, rotation_aug, flip_aug]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5bf919",
   "metadata": {},
   "source": [
    "### Helper function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "221f7340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_match_pred(x, model):\n",
    "#     get prediction of mix match model\n",
    "    pred_arr = None\n",
    "    \n",
    "#     Find the sum of all predictions from each augmentation test set\n",
    "    for aug in aug_list:\n",
    "        test_gen = aug.flow(x)\n",
    "        pred = model.predict_generator(test_gen, steps=len(x))\n",
    "        if pred_arr is None:\n",
    "            pred_arr = pred\n",
    "        else:\n",
    "            pred_arr = np.add(pred_arr, pred)\n",
    "#     Find the average of prediction      \n",
    "    pred_arr = np.true_divide(pred_arr, 3)\n",
    "    return pred_arr\n",
    "\n",
    "def get_extra_stacked(x, submodels, datagen):\n",
    "    \"\"\"Generate stacked output from submodels with augmented x for meta learner\"\"\"\n",
    "    stacked = None\n",
    "    print(len(x))\n",
    "    # augmentate x before predicting with submodels\n",
    "    pred_gen = datagen.flow(x)\n",
    "    for submodel in submodels:\n",
    "        if stacked is None:\n",
    "            stacked = submodel.predict_generator(pred_gen)\n",
    "        else:\n",
    "            # augmentate x before predicting with submodels\n",
    "            new_pred = submodel.predict_generator(pred_gen)\n",
    "            stacked = np.concatenate((stacked, new_pred), axis=1)\n",
    "    return stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "323e9855",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Sub model training---\n",
      "Train with augmented data\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 12:15:20.145172: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207/213 [============================>.] - ETA: 0s - loss: 0.8419 - accuracy: 0.6060"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 12:15:22.158078: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213/213 [==============================] - 2s 10ms/step - loss: 0.8383 - accuracy: 0.6080 - val_loss: 0.6444 - val_accuracy: 0.7162\n",
      "Epoch 2/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.6859 - accuracy: 0.6998 - val_loss: 0.5791 - val_accuracy: 0.7532\n",
      "Epoch 3/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.6521 - accuracy: 0.7259 - val_loss: 0.6924 - val_accuracy: 0.7174\n",
      "Epoch 4/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.6208 - accuracy: 0.7419 - val_loss: 0.5815 - val_accuracy: 0.7485\n",
      "Epoch 5/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.6052 - accuracy: 0.7515 - val_loss: 0.5819 - val_accuracy: 0.7456\n",
      "Epoch 6/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5885 - accuracy: 0.7601 - val_loss: 0.5419 - val_accuracy: 0.7726\n",
      "Epoch 7/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5768 - accuracy: 0.7666 - val_loss: 0.5330 - val_accuracy: 0.7891\n",
      "Epoch 8/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5855 - accuracy: 0.7657 - val_loss: 0.5247 - val_accuracy: 0.7873\n",
      "Epoch 9/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5879 - accuracy: 0.7620 - val_loss: 0.5866 - val_accuracy: 0.7562\n",
      "Epoch 10/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5707 - accuracy: 0.7726 - val_loss: 0.5066 - val_accuracy: 0.7914\n",
      "Epoch 11/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5594 - accuracy: 0.7739 - val_loss: 0.4788 - val_accuracy: 0.8061\n",
      "Epoch 12/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5654 - accuracy: 0.7689 - val_loss: 0.5174 - val_accuracy: 0.7949\n",
      "Epoch 13/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5544 - accuracy: 0.7767 - val_loss: 0.4988 - val_accuracy: 0.8008\n",
      "Epoch 14/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5306 - accuracy: 0.7854 - val_loss: 0.5149 - val_accuracy: 0.7973\n",
      "Epoch 15/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5340 - accuracy: 0.7810 - val_loss: 0.5631 - val_accuracy: 0.7632\n",
      "Epoch 16/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5314 - accuracy: 0.7830 - val_loss: 0.4684 - val_accuracy: 0.8155\n",
      "Epoch 17/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5337 - accuracy: 0.7863 - val_loss: 0.4896 - val_accuracy: 0.7985\n",
      "Epoch 18/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5320 - accuracy: 0.7898 - val_loss: 0.5978 - val_accuracy: 0.7485\n",
      "Epoch 19/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5355 - accuracy: 0.7788 - val_loss: 0.4751 - val_accuracy: 0.8114\n",
      "Epoch 20/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5250 - accuracy: 0.7913 - val_loss: 0.4728 - val_accuracy: 0.8085\n",
      "Epoch 21/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5314 - accuracy: 0.7800 - val_loss: 0.5106 - val_accuracy: 0.8032\n",
      "Epoch 22/40\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 0.5228 - accuracy: 0.7882 - val_loss: 0.4623 - val_accuracy: 0.8143\n",
      "Epoch 23/40\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 0.5138 - accuracy: 0.7944 - val_loss: 0.5422 - val_accuracy: 0.7732\n",
      "Epoch 24/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5064 - accuracy: 0.7974 - val_loss: 0.4960 - val_accuracy: 0.8043\n",
      "Epoch 25/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5275 - accuracy: 0.7901 - val_loss: 0.4962 - val_accuracy: 0.8049\n",
      "Epoch 26/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5155 - accuracy: 0.7923 - val_loss: 0.4567 - val_accuracy: 0.8190\n",
      "Epoch 27/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5134 - accuracy: 0.7979 - val_loss: 0.5581 - val_accuracy: 0.7720\n",
      "Epoch 28/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5058 - accuracy: 0.7955 - val_loss: 0.4646 - val_accuracy: 0.8090\n",
      "Epoch 29/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5038 - accuracy: 0.7973 - val_loss: 0.4703 - val_accuracy: 0.8173\n",
      "Epoch 30/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5035 - accuracy: 0.8013 - val_loss: 0.4998 - val_accuracy: 0.7955\n",
      "Epoch 31/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.4903 - accuracy: 0.8013 - val_loss: 0.4592 - val_accuracy: 0.8196\n",
      "Epoch 32/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5019 - accuracy: 0.7989 - val_loss: 0.4572 - val_accuracy: 0.8120\n",
      "Epoch 33/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5111 - accuracy: 0.7927 - val_loss: 0.4852 - val_accuracy: 0.8032\n",
      "Epoch 34/40\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 0.4944 - accuracy: 0.7999 - val_loss: 0.5269 - val_accuracy: 0.7949\n",
      "Epoch 35/40\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 0.4898 - accuracy: 0.8068 - val_loss: 0.5824 - val_accuracy: 0.7421\n",
      "Epoch 36/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.5146 - accuracy: 0.7926 - val_loss: 0.4904 - val_accuracy: 0.8096\n",
      "Epoch 37/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.4933 - accuracy: 0.8046 - val_loss: 0.5226 - val_accuracy: 0.7961\n",
      "Epoch 38/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.4917 - accuracy: 0.8030 - val_loss: 0.4609 - val_accuracy: 0.8184\n",
      "Epoch 39/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.4749 - accuracy: 0.8071 - val_loss: 0.4434 - val_accuracy: 0.8255\n",
      "Epoch 40/40\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.4907 - accuracy: 0.8051 - val_loss: 0.4918 - val_accuracy: 0.8173\n",
      "---Sub model training---\n",
      "Train with augmented data\n",
      "Epoch 1/15\n",
      "  1/186 [..............................] - ETA: 1:59 - loss: 1.3792 - accuracy: 0.4062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 12:16:40.319894: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/186 [============================>.] - ETA: 0s - loss: 1.2278 - accuracy: 0.4456"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 12:16:42.531275: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 3s 13ms/step - loss: 1.2256 - accuracy: 0.4469 - val_loss: 1.0545 - val_accuracy: 0.5417\n",
      "Epoch 2/15\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 1.0804 - accuracy: 0.5385 - val_loss: 0.9483 - val_accuracy: 0.6114\n",
      "Epoch 3/15\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.9449 - accuracy: 0.6293 - val_loss: 0.8852 - val_accuracy: 0.6422\n",
      "Epoch 4/15\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.9042 - accuracy: 0.6384 - val_loss: 0.8378 - val_accuracy: 0.6579\n",
      "Epoch 5/15\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.8812 - accuracy: 0.6550 - val_loss: 0.8007 - val_accuracy: 0.6670\n",
      "Epoch 6/15\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.8562 - accuracy: 0.6552 - val_loss: 0.7988 - val_accuracy: 0.6695\n",
      "Epoch 7/15\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.8436 - accuracy: 0.6665 - val_loss: 0.7867 - val_accuracy: 0.6847\n",
      "Epoch 8/15\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.8158 - accuracy: 0.6736 - val_loss: 0.8007 - val_accuracy: 0.6716\n",
      "Epoch 9/15\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.8491 - accuracy: 0.6576 - val_loss: 0.7771 - val_accuracy: 0.6897\n",
      "Epoch 10/15\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.8102 - accuracy: 0.6798 - val_loss: 0.7541 - val_accuracy: 0.7064\n",
      "Epoch 11/15\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.8115 - accuracy: 0.6744 - val_loss: 0.7799 - val_accuracy: 0.6721\n",
      "Epoch 12/15\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.8110 - accuracy: 0.6795 - val_loss: 0.7376 - val_accuracy: 0.6998\n",
      "Epoch 13/15\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7883 - accuracy: 0.6862 - val_loss: 0.7368 - val_accuracy: 0.6998\n",
      "Epoch 14/15\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7795 - accuracy: 0.6921 - val_loss: 0.7473 - val_accuracy: 0.7019\n",
      "Epoch 15/15\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7790 - accuracy: 0.6902 - val_loss: 0.7395 - val_accuracy: 0.7130\n",
      "5937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bc/1x56pk_j3glgqwsdp02fbltm0000gn/T/ipykernel_85409/706273855.py:25: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  stacked = submodel.predict_generator(pred_gen)\n",
      "2022-05-10 12:17:14.926125: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "/var/folders/bc/1x56pk_j3glgqwsdp02fbltm0000gn/T/ipykernel_85409/706273855.py:28: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  new_pred = submodel.predict_generator(pred_gen)\n",
      "2022-05-10 12:17:15.820001: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1979\n",
      "(5937, 7)\n",
      "(1979, 7)\n",
      "(5937,)\n",
      "(1979,)\n",
      "Epoch 1/15\n",
      "  8/186 [>.............................] - ETA: 1s - loss: 1.3540 - accuracy: 0.4258 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 12:17:17.443392: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - ETA: 0s - loss: 1.3268 - accuracy: 0.4122"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 12:17:18.728454: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 2s 8ms/step - loss: 1.3268 - accuracy: 0.4122 - val_loss: 1.3032 - val_accuracy: 0.4164\n",
      "Epoch 2/15\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 1.3077 - accuracy: 0.4122 - val_loss: 1.3008 - val_accuracy: 0.4164\n",
      "Epoch 3/15\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 1.3071 - accuracy: 0.4122 - val_loss: 1.3008 - val_accuracy: 0.4164\n",
      "Epoch 4/15\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 1.3072 - accuracy: 0.4122 - val_loss: 1.3004 - val_accuracy: 0.4164\n",
      "Epoch 5/15\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 1.3071 - accuracy: 0.4122 - val_loss: 1.3007 - val_accuracy: 0.4164\n",
      "Epoch 6/15\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 1.3071 - accuracy: 0.4122 - val_loss: 1.3005 - val_accuracy: 0.4164\n",
      "Epoch 7/15\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 1.3070 - accuracy: 0.4122 - val_loss: 1.3006 - val_accuracy: 0.4164\n",
      "Epoch 8/15\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 1.3069 - accuracy: 0.4122 - val_loss: 1.3011 - val_accuracy: 0.4164\n",
      "Epoch 9/15\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 1.3070 - accuracy: 0.4122 - val_loss: 1.3005 - val_accuracy: 0.4164\n",
      "Epoch 10/15\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 1.3070 - accuracy: 0.4122 - val_loss: 1.3004 - val_accuracy: 0.4164\n",
      "Epoch 11/15\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 1.3067 - accuracy: 0.4122 - val_loss: 1.3005 - val_accuracy: 0.4164\n",
      "Epoch 12/15\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 1.3069 - accuracy: 0.4122 - val_loss: 1.3002 - val_accuracy: 0.4164\n",
      "Epoch 13/15\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 1.3067 - accuracy: 0.4122 - val_loss: 1.3006 - val_accuracy: 0.4164\n",
      "Epoch 14/15\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 1.3067 - accuracy: 0.4122 - val_loss: 1.3016 - val_accuracy: 0.4164\n",
      "Epoch 15/15\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 1.3068 - accuracy: 0.4122 - val_loss: 1.3012 - val_accuracy: 0.4164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13bf86520>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extramodel_path = os.path.join(root, \"extra_submodels\")\n",
    "# data for 3 classes submodels\n",
    "sub_train = extra_datagen.flow(subx_train, suby_train)\n",
    "sub_val = extra_datagen.flow(subx_test, suby_test)\n",
    "\n",
    "# data for 4 classes submodels \n",
    "all_train = extra_datagen.flow(x_train, y_train)\n",
    "all_val = extra_datagen.flow(x_val, y_val)\n",
    "\n",
    "# train submodels with augmented x\n",
    "subclass_extra = three_class_submodel(extramodel_path, aug_train=sub_train, aug_val=sub_val)\n",
    "allclass_extra = all_class_submodel(extramodel_path, aug_train=all_train, aug_val=all_val)\n",
    "extra_submodels = [subclass_extra, allclass_extra]\n",
    "\n",
    "# get stacked x for meta-learner\n",
    "stacked_x_train = get_extra_stacked(x_train,extra_submodels, extra_datagen)\n",
    "stacked_x_val = get_extra_stacked(x_val,extra_submodels, extra_datagen)\n",
    "\n",
    "print(stacked_x_train.shape)\n",
    "print(stacked_x_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "extra_model = get_transfer_model()\n",
    "# fit model with stacked data from submodels\n",
    "extra_model.fit(stacked_x_train, y_train, epochs=15, validation_data=(stacked_x_val, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
