{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19ac42e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_tuner as kt\n",
    "from sklearn.metrics import classification_report\n",
    "import shutil\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# path variables to access files\n",
    "root = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7434e2ba",
   "metadata": {},
   "source": [
    "### Load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eff2688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = pd.read_csv(\"data_labels_mainData.csv\")\n",
    "extra_data = pd.read_csv(\"data_labels_extraData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8b54b5",
   "metadata": {},
   "source": [
    "### Get data from splitted folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63c61732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method get data for multiclass task (task 2)\n",
    "def celltype_classify_data_all(class_list):    \n",
    "    images = list()\n",
    "    labels = list()\n",
    "    \n",
    "    for i, label in enumerate(class_list):\n",
    "        # get image directory\n",
    "        img_dir = os.path.join(root, \"multiclass_task\", f\"{label}\")\n",
    "        \n",
    "        for img in os.listdir(img_dir):\n",
    "            img = cv2.imread(os.path.join(img_dir, img))\n",
    "            # resize to 0-1 for faster computation\n",
    "            resized = img / 255\n",
    "            images.append(resized)\n",
    "            labels.append(i)\n",
    "        \n",
    "    return (images, labels)\n",
    "\n",
    "all_class = [\"epithelial\", \"fibroblast\", \"inflammatory\", \"others\"]\n",
    "\n",
    "# method get data for multiclass task (task 2)\n",
    "def celltype_classify_data(class_list, mode):    \n",
    "    images = list()\n",
    "    labels = list()\n",
    "    \n",
    "    for i, label in enumerate(class_list):\n",
    "        # get image directory\n",
    "        img_dir = os.path.join(root, \"split3-multi-task\", f\"{mode}\", f\"{label}\")\n",
    "        \n",
    "        for img in os.listdir(img_dir):\n",
    "            img = cv2.imread(os.path.join(img_dir, img))\n",
    "            # resize to 0-1 for faster computation\n",
    "            resized = img / 255\n",
    "            images.append(resized)\n",
    "            labels.append(i)\n",
    "        \n",
    "    return (images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d50611",
   "metadata": {},
   "source": [
    "### Classification report method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6644e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_classification_report(y_test, prediction, print_out=True):\n",
    "    \"\"\"\n",
    "        Method to generate sklearn classification report with CNN multiclass output\n",
    "    \"\"\"\n",
    "    \n",
    "    encoded_pred = list()\n",
    "    # convert each CNN output (sparse categorial) to class\n",
    "    for pred in prediction:\n",
    "        encoded_pred.append(np.argmax(pred))\n",
    "\n",
    "    encoded_pred = np.array(encoded_pred)\n",
    "    if print_out:\n",
    "        print(classification_report(y_test, encoded_pred))\n",
    "    \n",
    "    return classification_report(y_test, encoded_pred, output_dict = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c1e833",
   "metadata": {},
   "source": [
    "### Structure of sub-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cf0ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiclass_model():\n",
    "    \"\"\"\n",
    "        Structure of model classifying 4 classes\n",
    "    \"\"\"\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    # First convo-pooling\n",
    "    # Convolutional layers (filter the image with a kernel)\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), strides=1,activation=\"relu\", input_shape=[27, 27, 3]))\n",
    "    # Max-pooling layers (reduce the size of the image by choosing max pixel at certain area)\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=1))\n",
    "    \n",
    "    # Second convo-pooling\n",
    "    # Convolutional layers (filter the image with a kernel)\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3),strides=1, activation=\"relu\"))\n",
    "    # Max-pooling layers (reduce the size of the image by choosing max pixel at certain area)\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2),strides=1))\n",
    "    \n",
    "    # Flatten input\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(4, activation=\"softmax\"))\n",
    "    # Compile model \n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_subclass_model():\n",
    "    \"\"\"\n",
    "        Structure of model classifying 3 classes\n",
    "    \"\"\"\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    # First convo-pooling\n",
    "    # Convolutional layers (filter the image with a kernel)\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", input_shape=[27, 27, 3]))\n",
    "    # Max-pooling layers (reduce the size of the image by choosing max pixel at certain area)\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    # Flatten input\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(3, activation=\"softmax\"))\n",
    "    # Compile model \n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef69168",
   "metadata": {},
   "source": [
    "### Methods to train and save submodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9341569",
   "metadata": {},
   "outputs": [],
   "source": [
    "submodel_path = os.path.join(root, \"multiclass_submodels\")   \n",
    "def three_class_submodel(file_path, aug_train = None, aug_val = None):\n",
    "    # path to model trained with 3 classes\n",
    "    subclass_path = path.join(file_path, \"subclass.h5\")\n",
    "    subclass_model = None\n",
    "    if not os.path.isfile(subclass_path) or keras.models.load_model(subclass_path) == None:\n",
    "        print(\"---Sub model training---\")\n",
    "        # train subclass that fit with 3 types of images\n",
    "        subclass_model = get_subclass_model()\n",
    "        \n",
    "        if aug_train is not None and aug_val is not None:\n",
    "            print(\"Train with augmented data\")\n",
    "            subclass_model.fit(aug_train, epochs=50, validation_data=aug_val)\n",
    "        else:\n",
    "            print(\"Train with non-augmented data\")\n",
    "            subclass_model.fit(subx_train, suby_train, epochs=40, validation_data=(subx_test, suby_test))\n",
    "            \n",
    "        subclass_model.save(subclass_path)\n",
    "        return subclass_model\n",
    "    else:\n",
    "        subclass_model = keras.models.load_model(subclass_path)\n",
    "        print(\"Model trained with 3 classes loaded\")\n",
    "        return subclass_model\n",
    "    \n",
    "def all_class_submodel(file_path, aug_train = None, aug_val = None):\n",
    "    allclass_path = path.join(file_path, \"allclass.h5\")\n",
    "    allclass_model = None\n",
    "    if not os.path.isfile(allclass_path) or keras.models.load_model(allclass_path) == None:\n",
    "        print(\"---Sub model training---\")\n",
    "        # train subclass that fit with 4 types of images\n",
    "        allclass_model = get_multiclass_model()\n",
    "        \n",
    "        if aug_train is not None and aug_val is not None:\n",
    "            print(\"Train with augmented data\")\n",
    "            allclass_model.fit(aug_train, epochs=50, validation_data=aug_val)\n",
    "        else:\n",
    "            print(\"Train with non-augmented data\")\n",
    "            allclass_model.fit(x_train, y_train, epochs=15, validation_data=(x_val, y_val))\n",
    "            \n",
    "        allclass_model.save(allclass_path)\n",
    "        return allclass_model\n",
    "    else:\n",
    "        allclass_model = keras.models.load_model(allclass_path)\n",
    "        print(\"Model trained with 4 classes loaded\")\n",
    "        return allclass_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c40b39",
   "metadata": {},
   "source": [
    "### Meta-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13a29b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transfer_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    # Flatten input\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    # Hidden layers\n",
    "    model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=\"softmax\"))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(3, activation=\"sigmoid\"))\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(4, activation=\"softmax\"))\n",
    "    # Compile model\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4c3911",
   "metadata": {},
   "source": [
    "### Get augmentated data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d672cb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images from folders\n",
    "all_class = [\"epithelial\", \"fibroblast\", \"inflammatory\", \"others\"]\n",
    "cell_img, cell_label = celltype_classify_data_all(all_class)\n",
    "cell_img, cell_label = np.array(cell_img), np.array(cell_label)\n",
    "\n",
    "sub_multiclass = [\"epithelial\", \"fibroblast\", \"inflammatory\"]\n",
    "sub_img, sub_label = celltype_classify_data_all(sub_multiclass)\n",
    "\n",
    "# # train and validate data for 3 classes\n",
    "# subx_train, subx_test, suby_train, suby_test = train_test_split(\n",
    "#     np.array(sub_img), np.array(sub_label), test_size=0.2\n",
    "# )\n",
    "\n",
    "# # train and validate data for 4 classes\n",
    "# x_train_val, x_test, y_train_val, y_test = train_test_split(\n",
    "#     cell_img, cell_label, test_size=0.2\n",
    "# )\n",
    "# x_train, x_val, y_train, y_val = train_test_split(\n",
    "#     x_train_val, y_train_val, test_size=0.25\n",
    "# )\n",
    "\n",
    "x_train, y_train = celltype_classify_data(all_class, \"train\")\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "x_val, y_val = celltype_classify_data(all_class, \"val\")\n",
    "x_val, y_val = np.array(x_val), np.array(y_val)\n",
    "\n",
    "x_test, y_test = celltype_classify_data(all_class, \"test\")\n",
    "x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "\n",
    "sub_multiclass = [\"epithelial\", \"fibroblast\", \"inflammatory\"]\n",
    "subx_train, suby_train = celltype_classify_data(sub_multiclass, \"train\")\n",
    "subx_train, suby_train = np.array(subx_train), np.array(suby_train)\n",
    "subx_test, suby_test = celltype_classify_data(sub_multiclass, \"val\")\n",
    "subx_test, suby_test = np.array(subx_test), np.array(suby_test)\n",
    "\n",
    "\n",
    "# get augmentation for extra training data\n",
    "extra_datagen = ImageDataGenerator(\n",
    "    rotation_range=60,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "\n",
    ")\n",
    "\n",
    "# fit augmentation with all images from all 4 classes\n",
    "extra_datagen.fit(cell_img)\n",
    "\n",
    "rotation_aug = ImageDataGenerator(\n",
    "    rotation_range=60\n",
    ")\n",
    "flip_aug = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    ")\n",
    "aug_list = [rotation_aug, flip_aug]\n",
    "\n",
    "# git aug_list with images\n",
    "for aug in aug_list:\n",
    "    aug.fit(cell_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5bf919",
   "metadata": {},
   "source": [
    "### Helper function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "221f7340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extra_stacked(x, submodels, datagen):\n",
    "    \"\"\"Generate stacked output from submodels with augmented x for meta learner\"\"\"\n",
    "    stacked = None\n",
    "    # augmentate x before predicting with submodels\n",
    "    pred_gen = datagen.flow(x, shuffle=False)\n",
    "    for submodel in submodels:\n",
    "        if stacked is None:\n",
    "            stacked = submodel.predict_generator(pred_gen)\n",
    "        else:\n",
    "            # augmentate x before predicting with submodels\n",
    "            new_pred = submodel.predict_generator(pred_gen)\n",
    "            stacked = np.concatenate((stacked, new_pred), axis=1)\n",
    "    return stacked\n",
    "\n",
    "def get_meta_prediction(x, sub_models, meta_learner):\n",
    "    \"\"\"Method to get meta model prediction \"\"\"\n",
    "    stacked_x = get_extra_stacked(x, extra_submodels,extra_datagen)\n",
    "    pred = meta_learner.predict(stacked_x)\n",
    "    return pred\n",
    "\n",
    "def avg_pred(x, aug_list, sub_models, meta_learner):\n",
    "    \"\"\"Method to get average meta model prediction of different augmentations of the same x\"\"\"\n",
    "    \n",
    "#     get prediction of mix match model\n",
    "    pred_arr = None\n",
    "#     Find the sum of all predictions from each augmentation test set\n",
    "    for aug in aug_list:\n",
    "        # get stacked output from submodels to let meta_learner predict \n",
    "        stacked_x = get_extra_stacked(x, sub_models, aug)\n",
    "        # predict with metta_learner\n",
    "        pred = meta_learner.predict(stacked_x)\n",
    "        \n",
    "        if pred_arr is None:\n",
    "            pred_arr = pred\n",
    "        else:\n",
    "            pred_arr = np.add(pred_arr, pred)\n",
    "#     Find the average of prediction      \n",
    "    pred_arr = np.true_divide(pred_arr, len(aug_list))\n",
    "    return pred_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08985ed",
   "metadata": {},
   "source": [
    "### Train metal model with augmented data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9eb1da",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "323e9855",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained with 3 classes loaded\n",
      "Model trained with 4 classes loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 10:24:13.030737: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-14 10:24:13.984174: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 10:24:15.654059: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - ETA: 0s - loss: 1.3341 - accuracy: 0.3063"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 10:24:17.433570: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 2s 10ms/step - loss: 1.3341 - accuracy: 0.3063 - val_loss: 1.1653 - val_accuracy: 0.7218\n",
      "Epoch 2/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 1.0391 - accuracy: 0.7550 - val_loss: 0.9708 - val_accuracy: 0.7309\n",
      "Epoch 3/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.8937 - accuracy: 0.7579 - val_loss: 0.8914 - val_accuracy: 0.7228\n",
      "Epoch 4/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.8293 - accuracy: 0.7553 - val_loss: 0.8501 - val_accuracy: 0.7264\n",
      "Epoch 5/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.7905 - accuracy: 0.7567 - val_loss: 0.8143 - val_accuracy: 0.7274\n",
      "Epoch 6/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.7553 - accuracy: 0.7596 - val_loss: 0.7880 - val_accuracy: 0.7284\n",
      "Epoch 7/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.7243 - accuracy: 0.7597 - val_loss: 0.7576 - val_accuracy: 0.7294\n",
      "Epoch 8/30\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.6941 - accuracy: 0.7624 - val_loss: 0.7402 - val_accuracy: 0.7339\n",
      "Epoch 9/30\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.6711 - accuracy: 0.7621 - val_loss: 0.7219 - val_accuracy: 0.7304\n",
      "Epoch 10/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.6540 - accuracy: 0.7618 - val_loss: 0.7072 - val_accuracy: 0.7279\n",
      "Epoch 11/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.6369 - accuracy: 0.7631 - val_loss: 0.6983 - val_accuracy: 0.7269\n",
      "Epoch 12/30\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.6257 - accuracy: 0.7754 - val_loss: 0.6803 - val_accuracy: 0.7506\n",
      "Epoch 13/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.6136 - accuracy: 0.7907 - val_loss: 0.6749 - val_accuracy: 0.7592\n",
      "Epoch 14/30\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.6037 - accuracy: 0.8025 - val_loss: 0.6769 - val_accuracy: 0.7592\n",
      "Epoch 15/30\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.5965 - accuracy: 0.8002 - val_loss: 0.6645 - val_accuracy: 0.7663\n",
      "Epoch 16/30\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.5902 - accuracy: 0.8062 - val_loss: 0.6572 - val_accuracy: 0.7673\n",
      "Epoch 17/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.5848 - accuracy: 0.8056 - val_loss: 0.6530 - val_accuracy: 0.7693\n",
      "Epoch 18/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.5813 - accuracy: 0.8044 - val_loss: 0.6503 - val_accuracy: 0.7678\n",
      "Epoch 19/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.5754 - accuracy: 0.8047 - val_loss: 0.6465 - val_accuracy: 0.7729\n",
      "Epoch 20/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.5699 - accuracy: 0.8042 - val_loss: 0.6490 - val_accuracy: 0.7719\n",
      "Epoch 21/30\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.5667 - accuracy: 0.8062 - val_loss: 0.6447 - val_accuracy: 0.7739\n",
      "Epoch 22/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.5635 - accuracy: 0.8096 - val_loss: 0.6471 - val_accuracy: 0.7709\n",
      "Epoch 23/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.5590 - accuracy: 0.8096 - val_loss: 0.6398 - val_accuracy: 0.7719\n",
      "Epoch 24/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.5561 - accuracy: 0.8101 - val_loss: 0.6395 - val_accuracy: 0.7688\n",
      "Epoch 25/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.5555 - accuracy: 0.8086 - val_loss: 0.6387 - val_accuracy: 0.7754\n",
      "Epoch 26/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.5508 - accuracy: 0.8108 - val_loss: 0.6391 - val_accuracy: 0.7724\n",
      "Epoch 27/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.5487 - accuracy: 0.8106 - val_loss: 0.6349 - val_accuracy: 0.7709\n",
      "Epoch 28/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.5463 - accuracy: 0.8083 - val_loss: 0.6346 - val_accuracy: 0.7699\n",
      "Epoch 29/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.5439 - accuracy: 0.8103 - val_loss: 0.6369 - val_accuracy: 0.7688\n",
      "Epoch 30/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.5428 - accuracy: 0.8147 - val_loss: 0.6372 - val_accuracy: 0.7699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bb8f1e80>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extramodel_path = os.path.join(root, \"extra_submodels\")\n",
    "# data for 3 classes submodels\n",
    "sub_train = extra_datagen.flow(subx_train, suby_train)\n",
    "sub_val = extra_datagen.flow(subx_test, suby_test)\n",
    "\n",
    "# data for 4 classes submodels \n",
    "all_train = extra_datagen.flow(x_train, y_train)\n",
    "all_val = extra_datagen.flow(x_val, y_val)\n",
    "\n",
    "# train submodels with augmented x\n",
    "subclass_extra = three_class_submodel(extramodel_path, aug_train=sub_train, aug_val=sub_val)\n",
    "allclass_extra = all_class_submodel(extramodel_path, aug_train=all_train, aug_val=all_val)\n",
    "extra_submodels = [subclass_extra, allclass_extra]\n",
    "\n",
    "# get stacked x for meta-learner\n",
    "stacked_x_train = get_extra_stacked(x_train,extra_submodels, extra_datagen)\n",
    "stacked_x_val = get_extra_stacked(x_val,extra_submodels, extra_datagen)\n",
    "\n",
    "extra_model = get_transfer_model()\n",
    "# fit model with stacked data from submodels\n",
    "extra_model.fit(stacked_x_train, y_train, epochs=30, validation_data=(stacked_x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814a72b8",
   "metadata": {},
   "source": [
    "### Average prediction of multiple augmentations vs single output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "003ad621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Stats for augmentations average prediction ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90       817\n",
      "           1       0.75      0.78      0.76       379\n",
      "           2       0.73      0.83      0.78       510\n",
      "           3       0.70      0.50      0.59       278\n",
      "\n",
      "    accuracy                           0.80      1984\n",
      "   macro avg       0.77      0.75      0.76      1984\n",
      "weighted avg       0.80      0.80      0.80      1984\n",
      "\n",
      "--- Stats for one output prediction ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90       817\n",
      "           1       0.71      0.76      0.74       379\n",
      "           2       0.71      0.81      0.76       510\n",
      "           3       0.64      0.41      0.50       278\n",
      "\n",
      "    accuracy                           0.78      1984\n",
      "   macro avg       0.74      0.72      0.73      1984\n",
      "weighted avg       0.78      0.78      0.78      1984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict with mix match (avg of multiple augmentations)\n",
    "avg = avg_pred(x_test, aug_list, extra_submodels, extra_model)\n",
    "# predict with one meta learner output\n",
    "meta_pred = get_meta_prediction(x_test, extra_submodels, extra_model)\n",
    "\n",
    "print(\"--- Stats for augmentations average prediction ---\")\n",
    "multiclass_classification_report(y_test,avg);\n",
    "\n",
    "print(\"--- Stats for one output prediction ---\")\n",
    "multiclass_classification_report(y_test,meta_pred);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7927245a",
   "metadata": {},
   "source": [
    "### Get extra dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7cd71565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_extra_epi():   \n",
    "    \"\"\"Load cancerous/epithelial in the extra dataset\"\"\"\n",
    "    images = list()\n",
    "    labels = list()\n",
    "    \n",
    "    # get image directory\n",
    "    img_dir = os.path.join(root, \"extra\", \"1\")\n",
    "\n",
    "    for img in os.listdir(img_dir):\n",
    "        img = cv2.imread(os.path.join(img_dir, img))\n",
    "        # resize to 0-1 for faster computation\n",
    "        resized = img / 255\n",
    "        images.append(resized)\n",
    "        \n",
    "        labels.append(0)\n",
    "    return (images, labels)\n",
    "\n",
    "def load_unlabeled():\n",
    "    \"\"\"Load unlabeled data from the extra dataset\"\"\"\n",
    "    images = list()\n",
    "    \n",
    "    # get image directory\n",
    "    img_dir = os.path.join(root, \"extra\", \"0\")\n",
    "\n",
    "    for img in os.listdir(img_dir):\n",
    "        img = cv2.imread(os.path.join(img_dir, img))\n",
    "        # resize to 0-1 for faster computation\n",
    "        resized = img / 255\n",
    "        images.append(resized)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84776fe8",
   "metadata": {},
   "source": [
    "### Load extra data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e63a0f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2990,)\n",
      "(7394, 27, 27, 3)\n"
     ]
    }
   ],
   "source": [
    "epi_train, epi_label = load_extra_epi()\n",
    "epi_train, epi_label = np.array(epi_train), np.array(epi_label)\n",
    "\n",
    "unlabeled = load_unlabeled()\n",
    "unlabeled = np.array(unlabeled)\n",
    "\n",
    "extra_model.save(path.join(root, \"extra_model.h5\"))\n",
    "\n",
    "print(epi_label.shape)\n",
    "print(unlabeled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1390bcd8",
   "metadata": {},
   "source": [
    "### Generate additional train data from extra dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9e0f80c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 10:31:34.525718: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "def encode_labels(pred_labels):\n",
    "    encoded_list = list()\n",
    "    # transform pseudo label to consists of integers\n",
    "    for i, pred in enumerate(pseudo_labels):\n",
    "        encoded = np.argmax(pred)\n",
    "        encoded_list.append(encoded)\n",
    "        \n",
    "    return np.array(encoded_list)\n",
    "\n",
    "# predict unlabeled data\n",
    "pseudo_labels = avg_pred(unlabeled, aug_list, extra_submodels, extra_model)\n",
    "pseudo_labels = encode_labels(pseudo_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cde69be",
   "metadata": {},
   "source": [
    "### Filter out epithelial to improve class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bf696f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4566,)\n",
      "(4566, 27, 27, 3)\n"
     ]
    }
   ],
   "source": [
    "epi_indices = np.where(pseudo_labels == 0)[0]\n",
    "\n",
    "pseudo_labels = np.delete(pseudo_labels, epi_indices, axis=0)\n",
    "unlabeled = np.delete(unlabeled, epi_indices, axis=0)\n",
    "\n",
    "print(pseudo_labels.shape)\n",
    "print(unlabeled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84997dc5",
   "metadata": {},
   "source": [
    "### Initial performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "539539c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial training accuracy 0.7842741935483871\n"
     ]
    }
   ],
   "source": [
    "og_performance = multiclass_classification_report(y_test,meta_pred, print_out=False)[\"accuracy\"]\n",
    "print(f\"Initial training accuracy {og_performance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f54c63",
   "metadata": {},
   "source": [
    "### Train extra data in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8462e281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 10:42:34.485116: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-14 10:42:35.008060: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-14 10:42:35.703853: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reload from most recent save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 10:42:40.636863: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-14 10:42:41.145164: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-14 10:42:41.796393: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reload from most recent save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 10:42:46.623279: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-14 10:42:47.117992: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-14 10:42:47.795638: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reload from most recent save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 10:42:52.708497: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-14 10:42:53.208499: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-14 10:42:53.886026: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reload from most recent save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 10:42:58.857608: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-14 10:43:02.818326: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-14 10:43:03.621991: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reload from most recent save\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "# mute warning \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "batches = 5\n",
    "extra_x_batch = np.array_split(unlabeled, batches)\n",
    "extra_y_batch = np.array_split(pseudo_labels, batches)\n",
    "\n",
    "# load extra model from last save point\n",
    "extra_model = keras.models.load_model(path.join(root, \"extra_model.h5\"))\n",
    "\n",
    "for i in range(batches):\n",
    "    # compute accuracy with test set\n",
    "    old_pred = get_meta_prediction(x_test, extra_submodels, extra_model)\n",
    "    old_accuracy = multiclass_classification_report(y_test,old_pred, print_out=False)[\"accuracy\"]\n",
    "    \n",
    "    # generate stacked x for train\n",
    "    stacked_batched = get_extra_stacked(extra_x_batch[i], extra_submodels, extra_datagen)\n",
    "    # fit with augmented batch\n",
    "    extra_model.fit(stacked_batched, extra_y_batch[i], epochs=10, validation_data=(stacked_x_val, y_val), verbose=0)\n",
    "    \n",
    "    # compute new accuracy with test set\n",
    "    new_pred = get_meta_prediction(x_test, extra_submodels, extra_model)\n",
    "    new_accuracy = multiclass_classification_report(y_test,new_pred, print_out=False)[\"accuracy\"]\n",
    "    \n",
    "    # save model if newly trained batch increase accuracy by at least 0.002\n",
    "    if (new_accuracy - old_accuracy) > 0.001:\n",
    "        print(\"Update model with newly trained data\")\n",
    "        extra_model.save(path.join(root, \"extra_model.h5\"))\n",
    "    else:\n",
    "        print(\"Reload from most recent save\")\n",
    "        # reload from old model/checkpoint if new batch decrease accuracy\n",
    "        extra_model = keras.models.load_model(path.join(root, \"extra_model.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "270acb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Stats for one output prediction ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90       817\n",
      "           1       0.73      0.79      0.76       379\n",
      "           2       0.72      0.82      0.76       510\n",
      "           3       0.69      0.46      0.56       278\n",
      "\n",
      "    accuracy                           0.79      1984\n",
      "   macro avg       0.76      0.74      0.74      1984\n",
      "weighted avg       0.79      0.79      0.79      1984\n",
      "\n",
      "Accuracy post extra training 0.7938508064516129\n",
      "--- Stats for augmentations average prediction ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       817\n",
      "           1       0.74      0.79      0.76       379\n",
      "           2       0.73      0.83      0.78       510\n",
      "           3       0.68      0.48      0.56       278\n",
      "\n",
      "    accuracy                           0.80      1984\n",
      "   macro avg       0.76      0.75      0.75      1984\n",
      "weighted avg       0.80      0.80      0.80      1984\n",
      "\n",
      "Accuracy post extra training 0.7998991935483871\n"
     ]
    }
   ],
   "source": [
    "# compute post train model output\n",
    "updated_pred = get_meta_prediction(x_test, extra_submodels, extra_model)\n",
    "updated_acc = multiclass_classification_report(y_test,updated_pred, print_out=False)['accuracy'];\n",
    "\n",
    "# compute average output from different augmentations\n",
    "updated_avg_pred = avg_pred(x_test, aug_list, extra_submodels, extra_model)\n",
    "updated_avg_acc = multiclass_classification_report(y_test,updated_avg_pred, print_out=False)['accuracy'];\n",
    "\n",
    "print(\"--- Stats for one output prediction ---\")\n",
    "multiclass_classification_report(y_test,updated_pred);\n",
    "print(f\"Accuracy post extra training {updated_acc}\")\n",
    "\n",
    "print(\"--- Stats for augmentations average prediction ---\")\n",
    "multiclass_classification_report(y_test,updated_avg_pred);\n",
    "print(f\"Accuracy post extra training {updated_avg_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
