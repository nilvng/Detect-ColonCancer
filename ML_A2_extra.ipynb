{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19ac42e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_tuner as kt\n",
    "from sklearn.metrics import classification_report\n",
    "import shutil\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# path variables to access files\n",
    "root = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7434e2ba",
   "metadata": {},
   "source": [
    "### Load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eff2688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = pd.read_csv(\"data_labels_mainData.csv\")\n",
    "extra_data = pd.read_csv(\"data_labels_extraData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8b54b5",
   "metadata": {},
   "source": [
    "### Get data from splitted folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63c61732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method get data for multiclass task (task 2)\n",
    "def celltype_classify_data(class_list):    \n",
    "    images = list()\n",
    "    labels = list()\n",
    "    \n",
    "    for i, label in enumerate(class_list):\n",
    "        # get image directory\n",
    "        img_dir = os.path.join(root, \"multiclass_task\", f\"{label}\")\n",
    "        \n",
    "        for img in os.listdir(img_dir):\n",
    "            img = cv2.imread(os.path.join(img_dir, img))\n",
    "            # resize to 0-1 for faster computation\n",
    "            resized = img / 255\n",
    "            images.append(resized)\n",
    "            labels.append(i)\n",
    "        \n",
    "    return (images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d50611",
   "metadata": {},
   "source": [
    "### Classification report method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6644e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_classification_report(y_test, prediction, print_out=True):\n",
    "    \"\"\"\n",
    "        Method to generate sklearn classification report with CNN multiclass output\n",
    "    \"\"\"\n",
    "    \n",
    "    encoded_pred = list()\n",
    "    # convert each CNN output (sparse categorial) to class\n",
    "    for pred in prediction:\n",
    "        encoded_pred.append(np.argmax(pred))\n",
    "\n",
    "    encoded_pred = np.array(encoded_pred)\n",
    "    if print_out:\n",
    "        print(classification_report(y_test, encoded_pred))\n",
    "    \n",
    "    return classification_report(y_test, encoded_pred, output_dict = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c1e833",
   "metadata": {},
   "source": [
    "### Structure of sub-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cf0ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiclass_model():\n",
    "    \"\"\"\n",
    "        Structure of model classifying 4 classes\n",
    "    \"\"\"\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    # First convo-pooling\n",
    "    # Convolutional layers (filter the image with a kernel)\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), strides=1,activation=\"relu\", input_shape=[27, 27, 3]))\n",
    "    # Max-pooling layers (reduce the size of the image by choosing max pixel at certain area)\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=1))\n",
    "    \n",
    "    # Second convo-pooling\n",
    "    # Convolutional layers (filter the image with a kernel)\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3),strides=1, activation=\"relu\"))\n",
    "    # Max-pooling layers (reduce the size of the image by choosing max pixel at certain area)\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2),strides=1))\n",
    "    \n",
    "    # Flatten input\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(4, activation=\"softmax\"))\n",
    "    # Compile model \n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_subclass_model():\n",
    "    \"\"\"\n",
    "        Structure of model classifying 3 classes\n",
    "    \"\"\"\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    # First convo-pooling\n",
    "    # Convolutional layers (filter the image with a kernel)\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", input_shape=[27, 27, 3]))\n",
    "    # Max-pooling layers (reduce the size of the image by choosing max pixel at certain area)\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    # Flatten input\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(3, activation=\"softmax\"))\n",
    "    # Compile model \n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef69168",
   "metadata": {},
   "source": [
    "### Methods to train and save submodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9341569",
   "metadata": {},
   "outputs": [],
   "source": [
    "submodel_path = os.path.join(root, \"multiclass_submodels\")   \n",
    "def three_class_submodel(file_path, aug_train = None, aug_val = None):\n",
    "    # path to model trained with 3 classes\n",
    "    subclass_path = path.join(file_path, \"subclass.h5\")\n",
    "    subclass_model = None\n",
    "    if not os.path.isfile(subclass_path) or keras.models.load_model(subclass_path) == None:\n",
    "        print(\"---Sub model training---\")\n",
    "        # train subclass that fit with 3 types of images\n",
    "        subclass_model = get_subclass_model()\n",
    "        \n",
    "        if aug_train is not None and aug_val is not None:\n",
    "            print(\"Train with augmented data\")\n",
    "            subclass_model.fit(aug_train, epochs=50, validation_data=aug_val)\n",
    "        else:\n",
    "            print(\"Train with non-augmented data\")\n",
    "            subclass_model.fit(subx_train, suby_train, epochs=40, validation_data=(subx_test, suby_test))\n",
    "            \n",
    "        subclass_model.save(subclass_path)\n",
    "        return subclass_model\n",
    "    else:\n",
    "        subclass_model = keras.models.load_model(subclass_path)\n",
    "        print(\"Model trained with 3 classes loaded\")\n",
    "        return subclass_model\n",
    "    \n",
    "def all_class_submodel(file_path, aug_train = None, aug_val = None):\n",
    "    allclass_path = path.join(file_path, \"allclass.h5\")\n",
    "    allclass_model = None\n",
    "    if not os.path.isfile(allclass_path) or keras.models.load_model(allclass_path) == None:\n",
    "        print(\"---Sub model training---\")\n",
    "        # train subclass that fit with 4 types of images\n",
    "        allclass_model = get_multiclass_model()\n",
    "        \n",
    "        if aug_train is not None and aug_val is not None:\n",
    "            print(\"Train with augmented data\")\n",
    "            allclass_model.fit(aug_train, epochs=50, validation_data=aug_val)\n",
    "        else:\n",
    "            print(\"Train with non-augmented data\")\n",
    "            allclass_model.fit(x_train, y_train, epochs=15, validation_data=(x_val, y_val))\n",
    "            \n",
    "        allclass_model.save(allclass_path)\n",
    "        return allclass_model\n",
    "    else:\n",
    "        allclass_model = keras.models.load_model(allclass_path)\n",
    "        print(\"Model trained with 4 classes loaded\")\n",
    "        return allclass_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c40b39",
   "metadata": {},
   "source": [
    "### Meta-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13a29b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transfer_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    # Flatten input\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    # Hidden layers\n",
    "    model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=\"softmax\"))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(3, activation=\"sigmoid\"))\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(4, activation=\"softmax\"))\n",
    "    # Compile model\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4c3911",
   "metadata": {},
   "source": [
    "### Get augmentated data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d672cb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images from folders\n",
    "all_class = [\"epithelial\", \"fibroblast\", \"inflammatory\", \"others\"]\n",
    "cell_img, cell_label = celltype_classify_data(all_class)\n",
    "cell_img, cell_label = np.array(cell_img), np.array(cell_label)\n",
    "\n",
    "sub_multiclass = [\"epithelial\", \"fibroblast\", \"inflammatory\"]\n",
    "sub_img, sub_label = celltype_classify_data(sub_multiclass)\n",
    "\n",
    "# train and validate data for 3 classes\n",
    "subx_train, subx_test, suby_train, suby_test = train_test_split(\n",
    "    np.array(sub_img), np.array(sub_label), test_size=0.2\n",
    ")\n",
    "\n",
    "# train and validate data for 4 classes\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(\n",
    "    cell_img, cell_label, test_size=0.2\n",
    ")\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train_val, y_train_val, test_size=0.25\n",
    ")\n",
    "\n",
    "# get augmentation for extra training data\n",
    "extra_datagen = ImageDataGenerator(\n",
    "#     width_shift_range=0.3,\n",
    "#     height_shift_range=0.3,\n",
    "    rotation_range=60,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "\n",
    ")\n",
    "\n",
    "# fit augmentation with all images from all 4 classes\n",
    "extra_datagen.fit(cell_img)\n",
    "\n",
    "# get augmentations for unlabeled data\n",
    "# shift_aug = ImageDataGenerator(\n",
    "#     width_shift_range=0.3,\n",
    "#     height_shift_range=0.3,\n",
    "# )\n",
    "rotation_aug = ImageDataGenerator(\n",
    "    rotation_range=60\n",
    ")\n",
    "flip_aug = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    ")\n",
    "aug_list = [rotation_aug, flip_aug]\n",
    "\n",
    "# git aug_list with images\n",
    "for aug in aug_list:\n",
    "    aug.fit(cell_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5bf919",
   "metadata": {},
   "source": [
    "### Helper function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "221f7340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extra_stacked(x, submodels, datagen):\n",
    "    \"\"\"Generate stacked output from submodels with augmented x for meta learner\"\"\"\n",
    "    stacked = None\n",
    "    # augmentate x before predicting with submodels\n",
    "    pred_gen = datagen.flow(x, shuffle=False)\n",
    "    for submodel in submodels:\n",
    "        if stacked is None:\n",
    "            stacked = submodel.predict_generator(pred_gen)\n",
    "        else:\n",
    "            # augmentate x before predicting with submodels\n",
    "            new_pred = submodel.predict_generator(pred_gen)\n",
    "            stacked = np.concatenate((stacked, new_pred), axis=1)\n",
    "    return stacked\n",
    "\n",
    "def mix_match_pred(x, aug_list, sub_models, meta_learner):\n",
    "#     get prediction of mix match model\n",
    "    pred_arr = None\n",
    "#     Find the sum of all predictions from each augmentation test set\n",
    "    for aug in aug_list:\n",
    "        # get stacked output from submodels to let meta_learner predict \n",
    "        stacked_x = get_extra_stacked(x, sub_models, aug)\n",
    "        # predict with metta_learner\n",
    "        pred = meta_learner.predict(stacked_x)\n",
    "        \n",
    "        if pred_arr is None:\n",
    "            pred_arr = pred\n",
    "        else:\n",
    "            pred_arr = np.add(pred_arr, pred)\n",
    "#     Find the average of prediction      \n",
    "    pred_arr = np.true_divide(pred_arr, len(aug_list))\n",
    "    return pred_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9eb1da",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "323e9855",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained with 3 classes loaded\n",
      "Model trained with 4 classes loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 12:05:38.639566: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-12 12:05:39.530415: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 12:05:41.111919: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - ETA: 0s - loss: 1.4116 - accuracy: 0.2978"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 12:05:42.570855: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 2s 8ms/step - loss: 1.4116 - accuracy: 0.2978 - val_loss: 1.2621 - val_accuracy: 0.7590\n",
      "Epoch 2/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 1.1815 - accuracy: 0.7472 - val_loss: 1.1079 - val_accuracy: 0.7585\n",
      "Epoch 3/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 1.0606 - accuracy: 0.7492 - val_loss: 0.9951 - val_accuracy: 0.7569\n",
      "Epoch 4/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.9521 - accuracy: 0.7500 - val_loss: 0.8999 - val_accuracy: 0.7585\n",
      "Epoch 5/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.8780 - accuracy: 0.7514 - val_loss: 0.8309 - val_accuracy: 0.7595\n",
      "Epoch 6/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.8208 - accuracy: 0.7534 - val_loss: 0.7894 - val_accuracy: 0.7600\n",
      "Epoch 7/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.7831 - accuracy: 0.7521 - val_loss: 0.7523 - val_accuracy: 0.7580\n",
      "Epoch 8/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.7553 - accuracy: 0.7522 - val_loss: 0.7250 - val_accuracy: 0.7585\n",
      "Epoch 9/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.7315 - accuracy: 0.7536 - val_loss: 0.7055 - val_accuracy: 0.7580\n",
      "Epoch 10/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.7122 - accuracy: 0.7522 - val_loss: 0.6831 - val_accuracy: 0.7610\n",
      "Epoch 11/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.6958 - accuracy: 0.7524 - val_loss: 0.6681 - val_accuracy: 0.7640\n",
      "Epoch 12/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.6834 - accuracy: 0.7522 - val_loss: 0.6561 - val_accuracy: 0.7640\n",
      "Epoch 13/30\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.6684 - accuracy: 0.7532 - val_loss: 0.6573 - val_accuracy: 0.7580\n",
      "Epoch 14/30\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.6571 - accuracy: 0.7546 - val_loss: 0.6337 - val_accuracy: 0.7605\n",
      "Epoch 15/30\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.6454 - accuracy: 0.7596 - val_loss: 0.6257 - val_accuracy: 0.7888\n",
      "Epoch 16/30\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.6361 - accuracy: 0.7785 - val_loss: 0.6126 - val_accuracy: 0.7933\n",
      "Epoch 17/30\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.6278 - accuracy: 0.7955 - val_loss: 0.6130 - val_accuracy: 0.8044\n",
      "Epoch 18/30\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.6207 - accuracy: 0.7991 - val_loss: 0.5999 - val_accuracy: 0.8125\n",
      "Epoch 19/30\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.6138 - accuracy: 0.8031 - val_loss: 0.5941 - val_accuracy: 0.8156\n",
      "Epoch 20/30\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.6068 - accuracy: 0.8068 - val_loss: 0.5901 - val_accuracy: 0.8120\n",
      "Epoch 21/30\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.6009 - accuracy: 0.8012 - val_loss: 0.5812 - val_accuracy: 0.8135\n",
      "Epoch 22/30\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.5956 - accuracy: 0.8073 - val_loss: 0.5766 - val_accuracy: 0.8166\n",
      "Epoch 23/30\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.5899 - accuracy: 0.8046 - val_loss: 0.5688 - val_accuracy: 0.8176\n",
      "Epoch 24/30\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.5843 - accuracy: 0.8058 - val_loss: 0.5657 - val_accuracy: 0.8171\n",
      "Epoch 25/30\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.5772 - accuracy: 0.8073 - val_loss: 0.5597 - val_accuracy: 0.8166\n",
      "Epoch 26/30\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.5714 - accuracy: 0.8098 - val_loss: 0.5512 - val_accuracy: 0.8151\n",
      "Epoch 27/30\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.5649 - accuracy: 0.8034 - val_loss: 0.5536 - val_accuracy: 0.8130\n",
      "Epoch 28/30\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.5603 - accuracy: 0.8078 - val_loss: 0.5410 - val_accuracy: 0.8181\n",
      "Epoch 29/30\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.5575 - accuracy: 0.8098 - val_loss: 0.5397 - val_accuracy: 0.8100\n",
      "Epoch 30/30\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.5522 - accuracy: 0.8068 - val_loss: 0.5363 - val_accuracy: 0.8161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x401386e50>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extramodel_path = os.path.join(root, \"extra_submodels\")\n",
    "# data for 3 classes submodels\n",
    "sub_train = extra_datagen.flow(subx_train, suby_train)\n",
    "sub_val = extra_datagen.flow(subx_test, suby_test)\n",
    "\n",
    "# data for 4 classes submodels \n",
    "all_train = extra_datagen.flow(x_train, y_train)\n",
    "all_val = extra_datagen.flow(x_val, y_val)\n",
    "\n",
    "# train submodels with augmented x\n",
    "subclass_extra = three_class_submodel(extramodel_path, aug_train=sub_train, aug_val=sub_val)\n",
    "allclass_extra = all_class_submodel(extramodel_path, aug_train=all_train, aug_val=all_val)\n",
    "extra_submodels = [subclass_extra, allclass_extra]\n",
    "\n",
    "# get stacked x for meta-learner\n",
    "stacked_x_train = get_extra_stacked(x_train,extra_submodels, extra_datagen)\n",
    "stacked_x_val = get_extra_stacked(x_val,extra_submodels, extra_datagen)\n",
    "\n",
    "extra_model = get_transfer_model()\n",
    "# fit model with stacked data from submodels\n",
    "extra_model.fit(stacked_x_train, y_train, epochs=30, validation_data=(stacked_x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "003ad621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bc/1x56pk_j3glgqwsdp02fbltm0000gn/T/ipykernel_57896/2772422593.py:8: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  stacked = submodel.predict_generator(pred_gen)\n",
      "/var/folders/bc/1x56pk_j3glgqwsdp02fbltm0000gn/T/ipykernel_57896/2772422593.py:11: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  new_pred = submodel.predict_generator(pred_gen)\n",
      "2022-05-11 21:24:00.713461: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90       826\n",
      "           1       0.82      0.75      0.78       375\n",
      "           2       0.76      0.87      0.81       509\n",
      "           3       0.73      0.54      0.62       270\n",
      "\n",
      "    accuracy                           0.82      1980\n",
      "   macro avg       0.80      0.77      0.78      1980\n",
      "weighted avg       0.82      0.82      0.82      1980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict with mix match (avg of multiple augmentations)\n",
    "meta_pred = mix_match_pred(x_test, aug_list, extra_submodels, extra_model)\n",
    "\n",
    "multiclass_classification_report(y_test,meta_pred);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7927245a",
   "metadata": {},
   "source": [
    "### Get extra dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cd71565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_extra_epi():   \n",
    "    \"\"\"Load cancerous/epithelial in the extra dataset\"\"\"\n",
    "    images = list()\n",
    "    labels = list()\n",
    "    \n",
    "    # get image directory\n",
    "    img_dir = os.path.join(root, \"extra\", \"1\")\n",
    "\n",
    "    for img in os.listdir(img_dir):\n",
    "        img = cv2.imread(os.path.join(img_dir, img))\n",
    "        # resize to 0-1 for faster computation\n",
    "        resized = img / 255\n",
    "        images.append(resized)\n",
    "        \n",
    "        labels.append(0)\n",
    "    return (images, labels)\n",
    "\n",
    "def load_unlabeled():\n",
    "    \"\"\"Load unlabeled data from the extra dataset\"\"\"\n",
    "    images = list()\n",
    "    \n",
    "    # get image directory\n",
    "    img_dir = os.path.join(root, \"extra\", \"0\")\n",
    "\n",
    "    for img in os.listdir(img_dir):\n",
    "        img = cv2.imread(os.path.join(img_dir, img))\n",
    "        # resize to 0-1 for faster computation\n",
    "        resized = img / 255\n",
    "        images.append(resized)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84776fe8",
   "metadata": {},
   "source": [
    "### Load extra data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e63a0f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2990,)\n"
     ]
    }
   ],
   "source": [
    "epi_train, epi_label = load_extra_epi()\n",
    "epi_train, epi_label = np.array(epi_train), np.array(epi_label)\n",
    "\n",
    "unlabeled = load_unlabeled()\n",
    "unlabeled = np.array(unlabeled)\n",
    "\n",
    "extra_model.save(path.join(root, \"extra_model.h5\"))\n",
    "\n",
    "print(epi_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8343a11",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0f30f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_model = keras.models.load_model(path.join(root, \"extra_model.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1390bcd8",
   "metadata": {},
   "source": [
    "### Generate additional train data from extra dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e0f80c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(pred_labels):\n",
    "    encoded_list = list()\n",
    "    # transform pseudo label to consists of integers\n",
    "    for i, pred in enumerate(pseudo_labels):\n",
    "        encoded = np.argmax(pred)\n",
    "        encoded_list.append(encoded)\n",
    "        \n",
    "    return np.array(encoded_list)\n",
    "\n",
    "# predict unlabeled data\n",
    "pseudo_labels = mix_match_pred(unlabeled, aug_list, extra_submodels, extra_model)\n",
    "pseudo_labels = encode_labels(pseudo_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f54c63",
   "metadata": {},
   "source": [
    "### Train extra data in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8462e281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 11:05:03.722938: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-12 11:05:05.670870: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-12 11:05:06.061246: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reload from most recent save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 11:05:11.039471: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-12 11:05:11.959846: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-12 11:05:12.289584: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reload from most recent save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 11:05:17.235666: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-12 11:05:18.147062: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-12 11:05:18.505805: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reload from most recent save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 11:05:23.442371: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-12 11:05:24.342245: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-12 11:05:24.693333: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reload from most recent save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 11:05:29.640273: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-12 11:05:30.560611: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-12 11:05:30.911396: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reload from most recent save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 11:05:35.813842: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-12 11:05:36.737024: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-12 11:05:37.076209: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reload from most recent save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 11:05:42.065285: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-12 11:05:42.991155: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-12 11:05:43.343149: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reload from most recent save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 11:05:48.218337: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-12 11:05:49.112061: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-12 11:05:49.467236: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reload from most recent save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 11:05:54.468000: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-12 11:05:55.376062: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-12 11:05:55.729180: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reload from most recent save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 11:06:00.663867: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-12 11:06:01.629219: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-12 11:06:02.008062: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reload from most recent save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 11:06:07.016897: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90       826\n",
      "           1       0.79      0.77      0.78       375\n",
      "           2       0.72      0.90      0.80       509\n",
      "           3       0.86      0.37      0.51       270\n",
      "\n",
      "    accuracy                           0.81      1980\n",
      "   macro avg       0.81      0.74      0.75      1980\n",
      "weighted avg       0.82      0.81      0.80      1980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "# mute warning \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "batches = 10\n",
    "extra_x_batch = np.array_split(unlabeled, batches)\n",
    "extra_y_batch = np.array_split(pseudo_labels, batches)\n",
    "\n",
    "# load extra model from last save point\n",
    "extra_model = keras.models.load_model(path.join(root, \"extra_model.h5\"))\n",
    "\n",
    "for i in range(batches):\n",
    "    # compute accuracy with test set\n",
    "    old_pred = mix_match_pred(x_test, aug_list, extra_submodels, extra_model)\n",
    "    old_accuracy = multiclass_classification_report(y_test,old_pred, print_out=False)[\"accuracy\"]\n",
    "    \n",
    "    # generate stacked x for train\n",
    "    stacked_batched = get_extra_stacked(extra_x_batch[i], extra_submodels, extra_datagen)\n",
    "    # fit with augmented batch\n",
    "    extra_model.fit(stacked_batched, extra_y_batch[i], epochs=10, validation_data=(stacked_x_val, y_val), verbose=0)\n",
    "    \n",
    "    # compute new accuracy with test set\n",
    "    new_pred = mix_match_pred(x_test, aug_list, extra_submodels, extra_model)\n",
    "    new_accuracy = multiclass_classification_report(y_test,new_pred, print_out=False)[\"accuracy\"]\n",
    "    \n",
    "    # save model if newly trained batch increase accuracy by at least 0.001\n",
    "    if (new_accuracy - old_accuracy) > 0.001:\n",
    "        print(\"Update model with newly trained data\")\n",
    "        extra_model.save(path.join(root, \"extra_model.h5\"))\n",
    "    else:\n",
    "        print(\"Reload from most recent save\")\n",
    "        # reload from old model/checkpoint if new batch decrease accuracy\n",
    "        extra_model = keras.models.load_model(path.join(root, \"extra_model.h5\"))\n",
    "    \n",
    "# compute new model stats\n",
    "updated_pred = mix_match_pred(x_test, aug_list, extra_submodels, extra_model)\n",
    "multiclass_classification_report(y_test,updated_pred);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
