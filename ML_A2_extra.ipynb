{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19ac42e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_tuner as kt\n",
    "from sklearn.metrics import classification_report\n",
    "import shutil\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# path variables to access files\n",
    "root = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7434e2ba",
   "metadata": {},
   "source": [
    "### Load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff2688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = pd.read_csv(\"data_labels_mainData.csv\")\n",
    "extra_data = pd.read_csv(\"data_labels_extraData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8b54b5",
   "metadata": {},
   "source": [
    "### Get data from splitted folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63c61732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method get data for multiclass task (task 2)\n",
    "def celltype_classify_data(class_list):    \n",
    "    images = list()\n",
    "    labels = list()\n",
    "    \n",
    "    for i, label in enumerate(class_list):\n",
    "        # get image directory\n",
    "        img_dir = os.path.join(root, \"multiclass_task\", f\"{label}\")\n",
    "        \n",
    "        for img in os.listdir(img_dir):\n",
    "            img = cv2.imread(os.path.join(img_dir, img))\n",
    "            # resize to 0-1 for faster computation\n",
    "            resized = img / 255\n",
    "            images.append(resized)\n",
    "            labels.append(i)\n",
    "        \n",
    "    return (images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d50611",
   "metadata": {},
   "source": [
    "### Classification report method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6644e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_classification_report(y_test, prediction):\n",
    "    \"\"\"\n",
    "        Method to generate sklearn classification report with CNN multiclass output\n",
    "    \"\"\"\n",
    "    \n",
    "    encoded_pred = list()\n",
    "    # convert each CNN output (sparse categorial) to class\n",
    "    for pred in prediction:\n",
    "        encoded_pred.append(np.argmax(pred))\n",
    "\n",
    "    encoded_pred = np.array(encoded_pred)\n",
    "    print(classification_report(y_test, encoded_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c1e833",
   "metadata": {},
   "source": [
    "### Structure of sub-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cf0ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiclass_model():\n",
    "    \"\"\"\n",
    "        Structure of model classifying 4 classes\n",
    "    \"\"\"\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    # First convo-pooling\n",
    "    # Convolutional layers (filter the image with a kernel)\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), strides=1,activation=\"relu\", input_shape=[27, 27, 3]))\n",
    "    # Max-pooling layers (reduce the size of the image by choosing max pixel at certain area)\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=1))\n",
    "    \n",
    "    # Second convo-pooling\n",
    "    # Convolutional layers (filter the image with a kernel)\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3),strides=1, activation=\"relu\"))\n",
    "    # Max-pooling layers (reduce the size of the image by choosing max pixel at certain area)\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2),strides=1))\n",
    "    \n",
    "    # Flatten input\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(2, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(4, activation=\"softmax\"))\n",
    "    # Compile model \n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_subclass_model():\n",
    "    \"\"\"\n",
    "        Structure of model classifying 3 classes\n",
    "    \"\"\"\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    # First convo-pooling\n",
    "    # Convolutional layers (filter the image with a kernel)\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", input_shape=[27, 27, 3]))\n",
    "    # Max-pooling layers (reduce the size of the image by choosing max pixel at certain area)\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    # Flatten input\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(3, activation=\"softmax\"))\n",
    "    # Compile model \n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef69168",
   "metadata": {},
   "source": [
    "### Methods to train and save submodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9341569",
   "metadata": {},
   "outputs": [],
   "source": [
    "submodel_path = os.path.join(root, \"multiclass_submodels\")   \n",
    "def three_class_submodel(file_path, aug_train = None, aug_val = None):\n",
    "    # path to model trained with 3 classes\n",
    "    subclass_path = path.join(file_path, \"subclass.h5\")\n",
    "    subclass_model = None\n",
    "    if not os.path.isfile(subclass_path) or keras.models.load_model(subclass_path) == None:\n",
    "        print(\"---Sub model training---\")\n",
    "        # train subclass that fit with 3 types of images\n",
    "        subclass_model = get_subclass_model()\n",
    "        \n",
    "        if aug_train is not None and aug_val is not None:\n",
    "            print(\"Train with augmented data\")\n",
    "            subclass_model.fit(aug_train, epochs=40, validation_data=aug_val)\n",
    "        else:\n",
    "            print(\"Train with non-augmented data\")\n",
    "            subclass_model.fit(subx_train, suby_train, epochs=40, validation_data=(subx_test, suby_test))\n",
    "            \n",
    "        subclass_model.save(subclass_path)\n",
    "        return subclass_model\n",
    "    else:\n",
    "        subclass_model = keras.models.load_model(subclass_path)\n",
    "        print(\"Model trained with 3 classes loaded\")\n",
    "        return subclass_model\n",
    "    \n",
    "def all_class_submodel(file_path, aug_train = None, aug_val = None):\n",
    "    allclass_path = path.join(file_path, \"allclass.h5\")\n",
    "    allclass_model = None\n",
    "    if not os.path.isfile(allclass_path) or keras.models.load_model(allclass_path) == None:\n",
    "        print(\"---Sub model training---\")\n",
    "        # train subclass that fit with 4 types of images\n",
    "        allclass_model = get_multiclass_model()\n",
    "        \n",
    "        if aug_train is not None and aug_val is not None:\n",
    "            print(\"Train with augmented data\")\n",
    "            allclass_model.fit(aug_train, epochs=40, validation_data=aug_val)\n",
    "        else:\n",
    "            print(\"Train with non-augmented data\")\n",
    "            allclass_model.fit(x_train, y_train, epochs=15, validation_data=(x_val, y_val))\n",
    "            \n",
    "        allclass_model.save(allclass_path)\n",
    "        return allclass_model\n",
    "    else:\n",
    "        allclass_model = keras.models.load_model(allclass_path)\n",
    "        print(\"Model trained with 4 classes loaded\")\n",
    "        return allclass_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c40b39",
   "metadata": {},
   "source": [
    "### Meta-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13a29b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transfer_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    # Flatten input\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    # Hidden layers\n",
    "    model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=\"softmax\"))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(3, activation=\"sigmoid\"))\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(4, activation=\"softmax\"))\n",
    "    # Compile model\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4c3911",
   "metadata": {},
   "source": [
    "### Get augmentated data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d672cb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images from folders\n",
    "all_class = [\"epithelial\", \"fibroblast\", \"inflammatory\", \"others\"]\n",
    "cell_img, cell_label = celltype_classify_data(all_class)\n",
    "cell_img, cell_label = np.array(cell_img), np.array(cell_label)\n",
    "\n",
    "sub_multiclass = [\"epithelial\", \"fibroblast\", \"inflammatory\"]\n",
    "sub_img, sub_label = celltype_classify_data(sub_multiclass)\n",
    "\n",
    "# train and validate data for 3 classes\n",
    "subx_train, subx_test, suby_train, suby_test = train_test_split(\n",
    "    np.array(sub_img), np.array(sub_label), test_size=0.2\n",
    ")\n",
    "\n",
    "# train and validate data for 4 classes\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(\n",
    "    cell_img, cell_label, test_size=0.2\n",
    ")\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train_val, y_train_val, test_size=0.25\n",
    ")\n",
    "\n",
    "# get augmentation for extra training data\n",
    "extra_datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    rotation_range=60,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "\n",
    ")\n",
    "\n",
    "# fit augmentation with all images from all 4 classes\n",
    "extra_datagen.fit(cell_img)\n",
    "\n",
    "# get augmentations for unlabeled data\n",
    "shift_aug = ImageDataGenerator(\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    ")\n",
    "rotation_aug = ImageDataGenerator(\n",
    "    rotation_range=60\n",
    ")\n",
    "flip_aug = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    ")\n",
    "aug_list = [shift_aug, rotation_aug, flip_aug]\n",
    "\n",
    "# git aug_list with images\n",
    "for aug in aug_list:\n",
    "    aug.fit(cell_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5bf919",
   "metadata": {},
   "source": [
    "### Helper function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "221f7340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extra_stacked(x, submodels, datagen):\n",
    "    \"\"\"Generate stacked output from submodels with augmented x for meta learner\"\"\"\n",
    "    stacked = None\n",
    "    # augmentate x before predicting with submodels\n",
    "    pred_gen = datagen.flow(x, shuffle=False)\n",
    "    for submodel in submodels:\n",
    "        if stacked is None:\n",
    "            stacked = submodel.predict_generator(pred_gen)\n",
    "        else:\n",
    "            # augmentate x before predicting with submodels\n",
    "            new_pred = submodel.predict_generator(pred_gen)\n",
    "            stacked = np.concatenate((stacked, new_pred), axis=1)\n",
    "    return stacked\n",
    "\n",
    "def mix_match_pred(x, aug_list, sub_models, meta_learner):\n",
    "#     get prediction of mix match model\n",
    "    pred_arr = None\n",
    "#     Find the sum of all predictions from each augmentation test set\n",
    "    for aug in aug_list:\n",
    "        # get stacked output from submodels to let meta_learner predict \n",
    "        stacked_x = get_extra_stacked(x, sub_models, aug)\n",
    "        # predict with metta_learner\n",
    "        pred = meta_learner.predict(stacked_x)\n",
    "        \n",
    "        if pred_arr is None:\n",
    "            pred_arr = pred\n",
    "        else:\n",
    "            pred_arr = np.add(pred_arr, pred)\n",
    "#     Find the average of prediction      \n",
    "    pred_arr = np.true_divide(pred_arr, len(aug_list))\n",
    "    return pred_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "323e9855",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained with 3 classes loaded\n",
      "---Sub model training---\n",
      "Train with augmented data\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 15:09:30.053694: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/186 [============================>.] - ETA: 0s - loss: 1.1897 - accuracy: 0.4691"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 15:09:32.532608: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 3s 14ms/step - loss: 1.1876 - accuracy: 0.4703 - val_loss: 1.1501 - val_accuracy: 0.4866\n",
      "Epoch 2/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 1.0552 - accuracy: 0.5632 - val_loss: 0.9443 - val_accuracy: 0.6301\n",
      "Epoch 3/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.9361 - accuracy: 0.6301 - val_loss: 0.8787 - val_accuracy: 0.6397\n",
      "Epoch 4/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.9252 - accuracy: 0.6328 - val_loss: 0.9073 - val_accuracy: 0.6382\n",
      "Epoch 5/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.8841 - accuracy: 0.6491 - val_loss: 0.9920 - val_accuracy: 0.5867\n",
      "Epoch 6/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.8764 - accuracy: 0.6454 - val_loss: 0.8330 - val_accuracy: 0.6534\n",
      "Epoch 7/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.8334 - accuracy: 0.6635 - val_loss: 0.9314 - val_accuracy: 0.6013\n",
      "Epoch 8/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.8142 - accuracy: 0.6764 - val_loss: 0.9289 - val_accuracy: 0.6311\n",
      "Epoch 9/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.8185 - accuracy: 0.6778 - val_loss: 0.8301 - val_accuracy: 0.6478\n",
      "Epoch 10/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7990 - accuracy: 0.6805 - val_loss: 0.7713 - val_accuracy: 0.6847\n",
      "Epoch 11/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7946 - accuracy: 0.6774 - val_loss: 0.8241 - val_accuracy: 0.6705\n",
      "Epoch 12/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7843 - accuracy: 0.6919 - val_loss: 0.8048 - val_accuracy: 0.6746\n",
      "Epoch 13/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7870 - accuracy: 0.6884 - val_loss: 0.7716 - val_accuracy: 0.6852\n",
      "Epoch 14/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7713 - accuracy: 0.6892 - val_loss: 0.9487 - val_accuracy: 0.6230\n",
      "Epoch 15/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7794 - accuracy: 0.6931 - val_loss: 0.7980 - val_accuracy: 0.6827\n",
      "Epoch 16/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7716 - accuracy: 0.6953 - val_loss: 0.7627 - val_accuracy: 0.6998\n",
      "Epoch 17/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7436 - accuracy: 0.7086 - val_loss: 0.7840 - val_accuracy: 0.6908\n",
      "Epoch 18/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7491 - accuracy: 0.7020 - val_loss: 0.7444 - val_accuracy: 0.7100\n",
      "Epoch 19/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7568 - accuracy: 0.7073 - val_loss: 0.7426 - val_accuracy: 0.7105\n",
      "Epoch 20/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7656 - accuracy: 0.6988 - val_loss: 0.8050 - val_accuracy: 0.6847\n",
      "Epoch 21/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7501 - accuracy: 0.7059 - val_loss: 0.7184 - val_accuracy: 0.7226\n",
      "Epoch 22/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7428 - accuracy: 0.7078 - val_loss: 0.7250 - val_accuracy: 0.7201\n",
      "Epoch 23/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7392 - accuracy: 0.7143 - val_loss: 0.7376 - val_accuracy: 0.7059\n",
      "Epoch 24/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7375 - accuracy: 0.7160 - val_loss: 0.7497 - val_accuracy: 0.6908\n",
      "Epoch 25/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7327 - accuracy: 0.7101 - val_loss: 0.7271 - val_accuracy: 0.7115\n",
      "Epoch 26/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7364 - accuracy: 0.7118 - val_loss: 0.7517 - val_accuracy: 0.7044\n",
      "Epoch 27/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7436 - accuracy: 0.7130 - val_loss: 0.8656 - val_accuracy: 0.6579\n",
      "Epoch 28/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7284 - accuracy: 0.7202 - val_loss: 0.7292 - val_accuracy: 0.7322\n",
      "Epoch 29/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7097 - accuracy: 0.7233 - val_loss: 0.6998 - val_accuracy: 0.7302\n",
      "Epoch 30/40\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.7253 - accuracy: 0.7135 - val_loss: 0.7181 - val_accuracy: 0.7180\n",
      "Epoch 31/40\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.7222 - accuracy: 0.7204 - val_loss: 0.7163 - val_accuracy: 0.7084\n",
      "Epoch 32/40\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.7158 - accuracy: 0.7239 - val_loss: 0.6978 - val_accuracy: 0.7251\n",
      "Epoch 33/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7279 - accuracy: 0.7197 - val_loss: 0.8007 - val_accuracy: 0.6902\n",
      "Epoch 34/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7130 - accuracy: 0.7238 - val_loss: 0.7074 - val_accuracy: 0.7155\n",
      "Epoch 35/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7082 - accuracy: 0.7308 - val_loss: 0.6978 - val_accuracy: 0.7327\n",
      "Epoch 36/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7228 - accuracy: 0.7165 - val_loss: 0.6863 - val_accuracy: 0.7438\n",
      "Epoch 37/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7297 - accuracy: 0.7143 - val_loss: 0.7710 - val_accuracy: 0.6847\n",
      "Epoch 38/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7146 - accuracy: 0.7258 - val_loss: 0.6893 - val_accuracy: 0.7383\n",
      "Epoch 39/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7129 - accuracy: 0.7244 - val_loss: 0.6710 - val_accuracy: 0.7377\n",
      "Epoch 40/40\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.7024 - accuracy: 0.7244 - val_loss: 0.7091 - val_accuracy: 0.7130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bc/1x56pk_j3glgqwsdp02fbltm0000gn/T/ipykernel_85409/2772422593.py:8: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  stacked = submodel.predict_generator(pred_gen)\n",
      "2022-05-10 15:11:02.117536: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "/var/folders/bc/1x56pk_j3glgqwsdp02fbltm0000gn/T/ipykernel_85409/2772422593.py:11: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  new_pred = submodel.predict_generator(pred_gen)\n",
      "2022-05-10 15:11:03.016164: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  1/186 [..............................] - ETA: 49s - loss: 1.3935 - accuracy: 0.3750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 15:11:04.666412: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/186 [============================>.] - ETA: 0s - loss: 1.2718 - accuracy: 0.4184"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 15:11:05.983049: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 2s 8ms/step - loss: 1.2706 - accuracy: 0.4179 - val_loss: 1.1643 - val_accuracy: 0.4017\n",
      "Epoch 2/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 1.0829 - accuracy: 0.4964 - val_loss: 1.0596 - val_accuracy: 0.5902\n",
      "Epoch 3/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 1.0108 - accuracy: 0.6348 - val_loss: 0.9926 - val_accuracy: 0.6847\n",
      "Epoch 4/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.9503 - accuracy: 0.7047 - val_loss: 0.9406 - val_accuracy: 0.6923\n",
      "Epoch 5/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.9090 - accuracy: 0.7123 - val_loss: 0.9062 - val_accuracy: 0.7029\n",
      "Epoch 6/30\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.8796 - accuracy: 0.7194 - val_loss: 0.8805 - val_accuracy: 0.7074\n",
      "Epoch 7/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.8568 - accuracy: 0.7211 - val_loss: 0.8607 - val_accuracy: 0.7054\n",
      "Epoch 8/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.8408 - accuracy: 0.7217 - val_loss: 0.8456 - val_accuracy: 0.7100\n",
      "Epoch 9/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.8252 - accuracy: 0.7226 - val_loss: 0.8326 - val_accuracy: 0.7125\n",
      "Epoch 10/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.8087 - accuracy: 0.7270 - val_loss: 0.8153 - val_accuracy: 0.7115\n",
      "Epoch 11/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.7956 - accuracy: 0.7249 - val_loss: 0.8054 - val_accuracy: 0.7145\n",
      "Epoch 12/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.7864 - accuracy: 0.7256 - val_loss: 0.7939 - val_accuracy: 0.7130\n",
      "Epoch 13/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.7765 - accuracy: 0.7265 - val_loss: 0.7869 - val_accuracy: 0.7125\n",
      "Epoch 14/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.7686 - accuracy: 0.7285 - val_loss: 0.7777 - val_accuracy: 0.7130\n",
      "Epoch 15/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.7577 - accuracy: 0.7297 - val_loss: 0.7692 - val_accuracy: 0.7125\n",
      "Epoch 16/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.7511 - accuracy: 0.7273 - val_loss: 0.7596 - val_accuracy: 0.7120\n",
      "Epoch 17/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.7431 - accuracy: 0.7280 - val_loss: 0.7519 - val_accuracy: 0.7145\n",
      "Epoch 18/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.7369 - accuracy: 0.7275 - val_loss: 0.7430 - val_accuracy: 0.7165\n",
      "Epoch 19/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.7328 - accuracy: 0.7303 - val_loss: 0.7394 - val_accuracy: 0.7115\n",
      "Epoch 20/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.7253 - accuracy: 0.7288 - val_loss: 0.7334 - val_accuracy: 0.7175\n",
      "Epoch 21/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.7242 - accuracy: 0.7251 - val_loss: 0.7293 - val_accuracy: 0.7145\n",
      "Epoch 22/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.7185 - accuracy: 0.7290 - val_loss: 0.7267 - val_accuracy: 0.7135\n",
      "Epoch 23/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.7157 - accuracy: 0.7287 - val_loss: 0.7202 - val_accuracy: 0.7155\n",
      "Epoch 24/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.7116 - accuracy: 0.7330 - val_loss: 0.7169 - val_accuracy: 0.7226\n",
      "Epoch 25/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.7084 - accuracy: 0.7339 - val_loss: 0.7136 - val_accuracy: 0.7221\n",
      "Epoch 26/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.7042 - accuracy: 0.7352 - val_loss: 0.7107 - val_accuracy: 0.7251\n",
      "Epoch 27/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.7028 - accuracy: 0.7366 - val_loss: 0.7076 - val_accuracy: 0.7226\n",
      "Epoch 28/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.7013 - accuracy: 0.7377 - val_loss: 0.7059 - val_accuracy: 0.7256\n",
      "Epoch 29/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.6984 - accuracy: 0.7379 - val_loss: 0.7006 - val_accuracy: 0.7362\n",
      "Epoch 30/30\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.6961 - accuracy: 0.7411 - val_loss: 0.7038 - val_accuracy: 0.7377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29561b4f0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extramodel_path = os.path.join(root, \"extra_submodels\")\n",
    "# data for 3 classes submodels\n",
    "sub_train = extra_datagen.flow(subx_train, suby_train)\n",
    "sub_val = extra_datagen.flow(subx_test, suby_test)\n",
    "\n",
    "# data for 4 classes submodels \n",
    "all_train = extra_datagen.flow(x_train, y_train)\n",
    "all_val = extra_datagen.flow(x_val, y_val)\n",
    "\n",
    "# train submodels with augmented x\n",
    "subclass_extra = three_class_submodel(extramodel_path, aug_train=sub_train, aug_val=sub_val)\n",
    "allclass_extra = all_class_submodel(extramodel_path, aug_train=all_train, aug_val=all_val)\n",
    "extra_submodels = [subclass_extra, allclass_extra]\n",
    "\n",
    "# get stacked x for meta-learner\n",
    "stacked_x_train = get_extra_stacked(x_train,extra_submodels, extra_datagen)\n",
    "stacked_x_val = get_extra_stacked(x_val,extra_submodels, extra_datagen)\n",
    "\n",
    "extra_model = get_transfer_model()\n",
    "# fit model with stacked data from submodels\n",
    "extra_model.fit(stacked_x_train, y_train, epochs=30, validation_data=(stacked_x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f49773ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bc/1x56pk_j3glgqwsdp02fbltm0000gn/T/ipykernel_85409/3989295597.py:2: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  pred = allclass_extra.predict_generator(pred_gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86       795\n",
      "           1       0.58      0.73      0.65       380\n",
      "           2       0.67      0.69      0.68       501\n",
      "           3       0.64      0.33      0.44       303\n",
      "\n",
      "    accuracy                           0.72      1979\n",
      "   macro avg       0.68      0.66      0.66      1979\n",
      "weighted avg       0.72      0.72      0.71      1979\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_gen = extra_datagen.flow(x_val, shuffle = False)\n",
    "pred = allclass_extra.predict_generator(pred_gen)\n",
    "\n",
    "multiclass_classification_report(y_val, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd40fb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bc/1x56pk_j3glgqwsdp02fbltm0000gn/T/ipykernel_85409/2772422593.py:8: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  stacked = submodel.predict_generator(pred_gen)\n",
      "/var/folders/bc/1x56pk_j3glgqwsdp02fbltm0000gn/T/ipykernel_85409/2772422593.py:11: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  new_pred = submodel.predict_generator(pred_gen)\n",
      "2022-05-10 15:15:45.234802: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.90       803\n",
      "           1       0.72      0.70      0.71       365\n",
      "           2       0.67      0.87      0.76       528\n",
      "           3       0.60      0.17      0.27       284\n",
      "\n",
      "    accuracy                           0.76      1980\n",
      "   macro avg       0.71      0.67      0.66      1980\n",
      "weighted avg       0.75      0.76      0.73      1980\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87       795\n",
      "           1       0.72      0.65      0.68       380\n",
      "           2       0.64      0.82      0.72       501\n",
      "           3       0.76      0.22      0.34       303\n",
      "\n",
      "    accuracy                           0.74      1979\n",
      "   macro avg       0.73      0.65      0.65      1979\n",
      "weighted avg       0.74      0.74      0.71      1979\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict with mix match (avg of multiple augmentations)\n",
    "meta_pred = mix_match_pred(x_test, aug_list, extra_submodels, extra_model)\n",
    "\n",
    "# predict with augmented data\n",
    "trained_pred = extra_model.predict(stacked_x_val)\n",
    "\n",
    "multiclass_classification_report(y_test,meta_pred)\n",
    "multiclass_classification_report(y_val,trained_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
