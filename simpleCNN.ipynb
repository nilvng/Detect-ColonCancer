{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16223 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 17:35:26.956436: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "path = \"Image_classification_data/split_binary-task/train\"\n",
    "train_bin = image_dataset_from_directory(path, labels=\"inferred\", image_size=(27,27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bin.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4057 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "path = \"Image_classification_data/split_binary-task/val\"\n",
    "val_bin = image_dataset_from_directory(path, labels=\"inferred\", image_size=(27,27))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rescale data, as neutral network will work with smaller range value better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_bin.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_bin.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense, InputLayer, MaxPooling2D, Dropout, Rescaling\n",
    "from keras.applications import xception\n",
    "from keras.losses import BinaryCrossentropy\n",
    "# model = xception(weights=None, input_shape=(256, 256, 3), classes=10)\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "model = Sequential([\n",
    "  Rescaling(1./255),\n",
    "  Conv2D(64, 3, activation='relu', padding='valid',input_shape = [27,27,3]),\n",
    "  MaxPooling2D(pool_size=(2,2),strides=2,padding = 'valid'),\n",
    "  Conv2D(64, 3, activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2,2),strides=2,padding = 'valid'),\n",
    "  Conv2D(128, 3, activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2,2),strides=2,padding = 'valid'),\n",
    "  Flatten(),\n",
    "Dense(128, activation='relu'),\n",
    "Dense(32, activation='relu'),\n",
    "Dense(1, activation=\"sigmoid\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.metrics import Precision, \n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=BinaryCrossentropy(),\n",
    "  metrics=['accuracy', Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fce2822cb90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fce2822cb90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "506/507 [============================>.] - ETA: 0s - loss: 0.4436 - accuracy: 0.7899 - precision: 0.7645WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fce298c1680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fce298c1680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "507/507 [==============================] - 22s 41ms/step - loss: 0.4433 - accuracy: 0.7901 - precision: 0.7646 - val_loss: 0.3638 - val_accuracy: 0.8568 - val_precision: 0.7738\n",
      "Epoch 2/10\n",
      "507/507 [==============================] - 18s 36ms/step - loss: 0.3534 - accuracy: 0.8454 - precision: 0.8011 - val_loss: 0.3245 - val_accuracy: 0.8721 - val_precision: 0.8097\n",
      "Epoch 3/10\n",
      "507/507 [==============================] - 19s 37ms/step - loss: 0.3278 - accuracy: 0.8617 - precision: 0.8238 - val_loss: 0.3003 - val_accuracy: 0.8805 - val_precision: 0.8438\n",
      "Epoch 4/10\n",
      "507/507 [==============================] - 18s 35ms/step - loss: 0.3110 - accuracy: 0.8702 - precision: 0.8335 - val_loss: 0.2931 - val_accuracy: 0.8812 - val_precision: 0.8392\n",
      "Epoch 5/10\n",
      "507/507 [==============================] - 19s 37ms/step - loss: 0.3007 - accuracy: 0.8752 - precision: 0.8409 - val_loss: 0.2926 - val_accuracy: 0.8790 - val_precision: 0.8129\n",
      "Epoch 6/10\n",
      "507/507 [==============================] - 17s 34ms/step - loss: 0.2879 - accuracy: 0.8823 - precision: 0.8495 - val_loss: 0.2831 - val_accuracy: 0.8846 - val_precision: 0.8546\n",
      "Epoch 7/10\n",
      "507/507 [==============================] - 17s 34ms/step - loss: 0.2808 - accuracy: 0.8855 - precision: 0.8544 - val_loss: 0.2835 - val_accuracy: 0.8827 - val_precision: 0.8647\n",
      "Epoch 8/10\n",
      "507/507 [==============================] - 17s 34ms/step - loss: 0.2730 - accuracy: 0.8877 - precision: 0.8567 - val_loss: 0.2872 - val_accuracy: 0.8809 - val_precision: 0.8640\n",
      "Epoch 9/10\n",
      "507/507 [==============================] - 18s 35ms/step - loss: 0.2648 - accuracy: 0.8914 - precision: 0.8615 - val_loss: 0.2826 - val_accuracy: 0.8837 - val_precision: 0.8438\n",
      "Epoch 10/10\n",
      "507/507 [==============================] - 18s 35ms/step - loss: 0.2558 - accuracy: 0.8963 - precision: 0.8681 - val_loss: 0.2837 - val_accuracy: 0.8837 - val_precision: 0.8453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fce287d9350>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae5e6dd5896681063d24cbfb179503b398deae949aacdf9655b1a7be467fbaeb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
