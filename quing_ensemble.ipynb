{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import keras_tuner as kt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def celltype_classify_data(class_list, root):    \n",
    "    images = list()\n",
    "    labels = list()\n",
    "    \n",
    "    for i, label in enumerate(class_list):\n",
    "        # get image directory\n",
    "        img_dir = os.path.join(root, f\"{label}\")\n",
    "        \n",
    "        for img in os.listdir(img_dir):\n",
    "            img = cv2.imread(os.path.join(img_dir, img))\n",
    "            # resize to 0-1 for faster computation\n",
    "            resized = img / 255\n",
    "            images.append(resized)\n",
    "            labels.append(i)\n",
    "        \n",
    "    return (images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs with 3 classes\n",
    "sub_multiclass = [\"epithelial\", \"fibroblast\",\"inflammatory\"]\n",
    "subcell_img, subcelltype_label = celltype_classify_data(sub_multiclass, root=\"Image_classification_data/multi-task\")\n",
    "subx_train, subx_test, suby_train, suby_test = train_test_split(\n",
    "    np.array(subcell_img), np.array(subcelltype_label), test_size=0.2\n",
    ")\n",
    "all_class = [\"epithelial\", \"fibroblast\",\"inflammatory\", \"others\"]\n",
    "# imgs with 4 classes\n",
    "cell_img, celltype_label = celltype_classify_data(all_class, root=\"Image_classification_data/multi-task\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    np.array(cell_img), np.array(celltype_label), test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Submodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3\n",
    "- Model train with data of 3 classes: epithelial, fibroblast, inflammatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subclass_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    # First convo-pooling\n",
    "    # Convolutional layers (filter the image with a kernel)\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", input_shape=[27, 27, 3]))\n",
    "    # Max-pooling layers (reduce the size of the image by choosing max pixel at certain area)\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    # Flatten input\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(3, activation=\"softmax\"))\n",
    "    # Compile model \n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 18:35:22.903182: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fe57681da70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fe57681da70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.7196 - accuracy: 0.6878WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fe55db86320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fe55db86320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "213/213 [==============================] - 8s 37ms/step - loss: 0.7189 - accuracy: 0.6882 - val_loss: 0.5095 - val_accuracy: 0.8067\n",
      "Epoch 2/15\n",
      "213/213 [==============================] - 6s 30ms/step - loss: 0.5022 - accuracy: 0.8014 - val_loss: 0.5441 - val_accuracy: 0.7955\n",
      "Epoch 3/15\n",
      "213/213 [==============================] - 6s 27ms/step - loss: 0.4615 - accuracy: 0.8248 - val_loss: 0.5149 - val_accuracy: 0.7949\n",
      "Epoch 4/15\n",
      "213/213 [==============================] - 6s 27ms/step - loss: 0.4424 - accuracy: 0.8256 - val_loss: 0.4301 - val_accuracy: 0.8355\n",
      "Epoch 5/15\n",
      "213/213 [==============================] - 6s 26ms/step - loss: 0.3974 - accuracy: 0.8459 - val_loss: 0.4403 - val_accuracy: 0.8255\n",
      "Epoch 6/15\n",
      "213/213 [==============================] - 6s 27ms/step - loss: 0.3862 - accuracy: 0.8493 - val_loss: 0.5028 - val_accuracy: 0.8085\n",
      "Epoch 7/15\n",
      "213/213 [==============================] - 6s 27ms/step - loss: 0.3684 - accuracy: 0.8610 - val_loss: 0.4332 - val_accuracy: 0.8384\n",
      "Epoch 8/15\n",
      "213/213 [==============================] - 6s 28ms/step - loss: 0.3232 - accuracy: 0.8749 - val_loss: 0.4682 - val_accuracy: 0.8243\n",
      "Epoch 9/15\n",
      "213/213 [==============================] - 6s 30ms/step - loss: 0.3082 - accuracy: 0.8837 - val_loss: 0.5250 - val_accuracy: 0.8043\n",
      "Epoch 10/15\n",
      "213/213 [==============================] - 6s 28ms/step - loss: 0.2617 - accuracy: 0.9023 - val_loss: 0.5146 - val_accuracy: 0.8196\n",
      "Epoch 11/15\n",
      "213/213 [==============================] - 6s 28ms/step - loss: 0.2460 - accuracy: 0.9067 - val_loss: 0.5501 - val_accuracy: 0.8090\n",
      "Epoch 12/15\n",
      "213/213 [==============================] - 6s 26ms/step - loss: 0.2035 - accuracy: 0.9232 - val_loss: 0.6288 - val_accuracy: 0.8167\n",
      "Epoch 13/15\n",
      "213/213 [==============================] - 6s 28ms/step - loss: 0.1860 - accuracy: 0.9279 - val_loss: 0.6438 - val_accuracy: 0.8220\n",
      "Epoch 14/15\n",
      "213/213 [==============================] - 8s 38ms/step - loss: 0.1621 - accuracy: 0.9390 - val_loss: 0.6474 - val_accuracy: 0.8208\n",
      "Epoch 15/15\n",
      "213/213 [==============================] - 7s 31ms/step - loss: 0.1421 - accuracy: 0.9492 - val_loss: 0.8257 - val_accuracy: 0.8108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe55a08da90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train subclass that fit with 3 types of images\n",
    "subclass_model = get_subclass_model()\n",
    "subclass_model.fit(subx_train, suby_train, epochs=15, validation_data=(subx_test, suby_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4\n",
    "- Model train with data of 4 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_multiclass_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    # First convo-pooling\n",
    "    \n",
    "    # Convolutional layers (filter the image with a kernel)\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), strides=1,activation=\"relu\", input_shape=[27, 27, 3]))\n",
    "    # Max-pooling layers (reduce the size of the image by choosing max pixel at certain area)\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=1))\n",
    "    \n",
    "    # Convolutional layers (filter the image with a kernel)\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3),strides=1, activation=\"relu\"))\n",
    "    # Max-pooling layers (reduce the size of the image by choosing max pixel at certain area)\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2),strides=1))\n",
    "    \n",
    "    # Flatten input\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(4, activation=\"softmax\"))\n",
    "    # Compile model \n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fe592b415f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fe592b415f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "248/248 [==============================] - ETA: 0s - loss: 1.1004 - accuracy: 0.5360WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fe55a04fe60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fe55a04fe60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "248/248 [==============================] - 35s 137ms/step - loss: 1.1004 - accuracy: 0.5360 - val_loss: 0.9787 - val_accuracy: 0.6449\n",
      "Epoch 2/15\n",
      "248/248 [==============================] - 32s 130ms/step - loss: 0.8717 - accuracy: 0.6623 - val_loss: 0.8397 - val_accuracy: 0.6652\n",
      "Epoch 3/15\n",
      "248/248 [==============================] - 30s 118ms/step - loss: 0.7813 - accuracy: 0.6934 - val_loss: 0.7691 - val_accuracy: 0.6828\n",
      "Epoch 4/15\n",
      "248/248 [==============================] - 28s 113ms/step - loss: 0.7635 - accuracy: 0.6919 - val_loss: 0.7492 - val_accuracy: 0.7066\n",
      "Epoch 5/15\n",
      "248/248 [==============================] - 30s 119ms/step - loss: 0.7189 - accuracy: 0.7158 - val_loss: 0.7558 - val_accuracy: 0.6980\n",
      "Epoch 6/15\n",
      "248/248 [==============================] - 29s 115ms/step - loss: 0.6782 - accuracy: 0.7346 - val_loss: 0.6791 - val_accuracy: 0.7338\n",
      "Epoch 7/15\n",
      "248/248 [==============================] - 34s 137ms/step - loss: 0.6549 - accuracy: 0.7449 - val_loss: 0.6874 - val_accuracy: 0.7227\n",
      "Epoch 8/15\n",
      "248/248 [==============================] - 31s 123ms/step - loss: 0.6059 - accuracy: 0.7607 - val_loss: 0.7558 - val_accuracy: 0.6924\n",
      "Epoch 9/15\n",
      "248/248 [==============================] - 27s 110ms/step - loss: 0.5769 - accuracy: 0.7778 - val_loss: 0.7336 - val_accuracy: 0.7247\n",
      "Epoch 10/15\n",
      "248/248 [==============================] - 28s 113ms/step - loss: 0.5359 - accuracy: 0.7923 - val_loss: 0.7372 - val_accuracy: 0.7157\n",
      "Epoch 11/15\n",
      "248/248 [==============================] - 31s 124ms/step - loss: 0.4839 - accuracy: 0.8147 - val_loss: 0.7863 - val_accuracy: 0.7091\n",
      "Epoch 12/15\n",
      "248/248 [==============================] - 31s 124ms/step - loss: 0.4464 - accuracy: 0.8314 - val_loss: 0.7761 - val_accuracy: 0.7288\n",
      "Epoch 13/15\n",
      "248/248 [==============================] - 36s 145ms/step - loss: 0.3893 - accuracy: 0.8597 - val_loss: 0.9835 - val_accuracy: 0.6808\n",
      "Epoch 14/15\n",
      "248/248 [==============================] - 33s 135ms/step - loss: 0.3725 - accuracy: 0.8634 - val_loss: 0.8992 - val_accuracy: 0.7136\n",
      "Epoch 15/15\n",
      "248/248 [==============================] - 31s 124ms/step - loss: 0.3119 - accuracy: 0.8845 - val_loss: 0.9459 - val_accuracy: 0.7162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe5597d9f50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_multiclass_model()\n",
    "\n",
    "model.fit(x_train, y_train, epochs=15, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the ensemble\n",
    "1. get the output result of model 3 and model 4\n",
    "2. concatenate the results in order to put it into the meta-learner = stacked_x\n",
    "3. Train the model with that stacked_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transfer_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    # Flatten input\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    # Hidden layers\n",
    "    model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=\"softmax\"))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(3, activation=\"sigmoid\"))\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(4, activation=\"softmax\"))\n",
    "    # Compile model\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fe5360b6f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fe5360b6f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "239/248 [===========================>..] - ETA: 0s - loss: 1.2701 - accuracy: 0.3133WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fe53607ab00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fe53607ab00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 1.2625 - accuracy: 0.3167 - val_loss: 1.1413 - val_accuracy: 0.4227\n",
      "Epoch 2/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.9398 - accuracy: 0.6362 - val_loss: 0.9609 - val_accuracy: 0.7278\n",
      "Epoch 3/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.7838 - accuracy: 0.8223 - val_loss: 0.8774 - val_accuracy: 0.7268\n",
      "Epoch 4/30\n",
      "248/248 [==============================] - 1s 4ms/step - loss: 0.6915 - accuracy: 0.8244 - val_loss: 0.8369 - val_accuracy: 0.7298\n",
      "Epoch 5/30\n",
      "248/248 [==============================] - 1s 4ms/step - loss: 0.6318 - accuracy: 0.8253 - val_loss: 0.8031 - val_accuracy: 0.7298\n",
      "Epoch 6/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.5919 - accuracy: 0.8239 - val_loss: 0.7987 - val_accuracy: 0.7253\n",
      "Epoch 7/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.5555 - accuracy: 0.8257 - val_loss: 0.7648 - val_accuracy: 0.7303\n",
      "Epoch 8/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.5279 - accuracy: 0.8245 - val_loss: 0.7586 - val_accuracy: 0.7278\n",
      "Epoch 9/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.5063 - accuracy: 0.8247 - val_loss: 0.7520 - val_accuracy: 0.7258\n",
      "Epoch 10/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.4881 - accuracy: 0.8263 - val_loss: 0.7504 - val_accuracy: 0.7212\n",
      "Epoch 11/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.4742 - accuracy: 0.8267 - val_loss: 0.7269 - val_accuracy: 0.7308\n",
      "Epoch 12/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.4630 - accuracy: 0.8276 - val_loss: 0.7472 - val_accuracy: 0.7253\n",
      "Epoch 13/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.4526 - accuracy: 0.8266 - val_loss: 0.7417 - val_accuracy: 0.7258\n",
      "Epoch 14/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.4440 - accuracy: 0.8283 - val_loss: 0.7325 - val_accuracy: 0.7263\n",
      "Epoch 15/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.4366 - accuracy: 0.8288 - val_loss: 0.7305 - val_accuracy: 0.7308\n",
      "Epoch 16/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.4201 - accuracy: 0.8286 - val_loss: 0.7260 - val_accuracy: 0.7313\n",
      "Epoch 17/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.3951 - accuracy: 0.8883 - val_loss: 0.7543 - val_accuracy: 0.7535\n",
      "Epoch 18/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.3667 - accuracy: 0.9295 - val_loss: 0.7439 - val_accuracy: 0.7566\n",
      "Epoch 19/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.3410 - accuracy: 0.9304 - val_loss: 0.7730 - val_accuracy: 0.7525\n",
      "Epoch 20/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.3181 - accuracy: 0.9322 - val_loss: 0.7768 - val_accuracy: 0.7545\n",
      "Epoch 21/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.3029 - accuracy: 0.9301 - val_loss: 0.7872 - val_accuracy: 0.7551\n",
      "Epoch 22/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.2900 - accuracy: 0.9327 - val_loss: 0.7867 - val_accuracy: 0.7591\n",
      "Epoch 23/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.2799 - accuracy: 0.9327 - val_loss: 0.8174 - val_accuracy: 0.7561\n",
      "Epoch 24/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.2744 - accuracy: 0.9323 - val_loss: 0.8045 - val_accuracy: 0.7535\n",
      "Epoch 25/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.2641 - accuracy: 0.9339 - val_loss: 0.8031 - val_accuracy: 0.7566\n",
      "Epoch 26/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.2582 - accuracy: 0.9343 - val_loss: 0.8157 - val_accuracy: 0.7576\n",
      "Epoch 27/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.2530 - accuracy: 0.9352 - val_loss: 0.7792 - val_accuracy: 0.7631\n",
      "Epoch 28/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.2466 - accuracy: 0.9351 - val_loss: 0.7987 - val_accuracy: 0.7672\n",
      "Epoch 29/30\n",
      "248/248 [==============================] - 1s 3ms/step - loss: 0.2401 - accuracy: 0.9363 - val_loss: 0.7989 - val_accuracy: 0.7646\n",
      "Epoch 30/30\n",
      "248/248 [==============================] - 1s 2ms/step - loss: 0.2326 - accuracy: 0.9375 - val_loss: 0.7884 - val_accuracy: 0.7581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe533948e50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# get transfered model (3 classes model) and predict with 4 types of images\n",
    "transfer_x_train = subclass_model.predict(x_train)\n",
    "transfer_x_test = subclass_model.predict(x_test)\n",
    "\n",
    "# get base model (4 classes model) and predict to get another x\n",
    "base_x = model.predict(x_train)\n",
    "base_x_test = model.predict(x_test)\n",
    "\n",
    "stacked_x_train = np.concatenate((transfer_x_train, base_x), axis=1)\n",
    "stack_x_test = np.concatenate((transfer_x_test, base_x_test), axis=1)\n",
    "\n",
    "transfer_model = get_transfer_model()\n",
    "transfer_model.fit(stacked_x_train, y_train, epochs=30, validation_data=(stack_x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f85430522e24dcceb49f547c8042b2746187a0750be8e55b7097447c175006b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('keras-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
