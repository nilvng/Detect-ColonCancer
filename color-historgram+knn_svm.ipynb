{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n",
    "sources: \n",
    "- [knn for image classfication](https://pyimagesearch.com/2016/08/08/k-nn-classifier-for-image-classification/)\n",
    "- [Color Histogram for Image Searcher](https://pyimagesearch.com/2014/12/01/complete-guide-building-image-search-engine-python-opencv/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.5.5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Color Descriptor aka Color Histogram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorDescriptor:\n",
    "\n",
    "    def __init__(self, bins):\n",
    "\t\t# store the number of bins for the 3D histogram\n",
    "        self.bins = bins\n",
    "    \n",
    "    def histogram(self,image, mask):\n",
    "        \t# extract a 3D color histogram from the masked region of the\n",
    "\t\t# image, using the supplied number of bins per channel\n",
    "        hist = cv2.calcHist([image], [0, 1, 2], mask, self.bins, [0, 256, 0, 256, 0, 256])\n",
    "\t\t# normalize the histogram \n",
    "        hist = cv2.normalize(hist, hist).flatten() # help the difference in image dimension\n",
    "\t\t# return the histogram\n",
    "        return hist\n",
    "    def describe(self, image):\n",
    "\t\t# convert the image to the HSV color space and initialize\n",
    "\t\t# the features used to quantify the image\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        features = []\n",
    "\t\t# grab the dimensions and compute the center of the image\n",
    "        (h, w) = image.shape[:2]\n",
    "        (cX, cY) = (int(w * 0.5), int(h * 0.5))\n",
    "\n",
    "        # Divide image into 5 regions (top-left,\n",
    "        # top-right, bottom-right, bottom-left, center oval)\n",
    "        segments = [(0, cX, 0, cY), (cX, w, 0, cY), (cX, w, cY, h),\n",
    "            (0, cX, cY, h)]\n",
    "        # construct an elliptical mask representing the center of the\n",
    "        # image\n",
    "        (axesX, axesY) = (int(w * 0.75) // 2, int(h * 0.75) // 2)\n",
    "        ellipMask = np.zeros(image.shape[:2], dtype = \"uint8\") # center\n",
    "        cv2.ellipse(ellipMask, (cX, cY), (axesX, axesY), 0, 0, 360, 255, -1)\n",
    "        \n",
    "        # loop over the segments\n",
    "        for (startX, endX, startY, endY) in segments:\n",
    "            # construct a mask for each corner of the image, subtracting\n",
    "            # the elliptical center from it\n",
    "            cornerMask = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
    "            cv2.rectangle(cornerMask, (startX, startY), (endX, endY), 255, -1)\n",
    "            cornerMask = cv2.subtract(cornerMask, ellipMask)\n",
    "            # extract a color histogram from the image, then update the\n",
    "            # feature vector\n",
    "            hist = self.histogram(image, cornerMask)\n",
    "            features.extend(hist)\n",
    "        # extract a color histogram from the elliptical region and\n",
    "        # update the feature vector\n",
    "        hist = self.histogram(image, ellipMask)\n",
    "        features.extend(hist)\n",
    "        # return the feature vector\n",
    "        return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def load_data(labelNames, root):    \n",
    "    images = list()\n",
    "    labels = list()\n",
    "    descriptor = ColorDescriptor(bins=[8,8,8])\n",
    "    \n",
    "    for label in labelNames:\n",
    "            # get image directory\n",
    "            img_dir = os.path.join(root, f\"{label}\")\n",
    "            \n",
    "            for img in os.listdir(img_dir):\n",
    "                img = np.array(Image.open(os.path.join(img_dir, img),'r'))\n",
    "                feature = descriptor.describe(img)\n",
    "                images.append(feature)\n",
    "                labels.append(int(label))\n",
    "    return (images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/Users/lap11353-local/Desktop/ML/A2/Image_classification_data/split_binary-task/train\"\n",
    "trainX, trainY = load_data([0,1], train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path = \"/Users/lap11353-local/Desktop/ML/A2/Image_classification_data/split_binary-task/val\"\n",
    "val_X, val_Y = load_data([\"0\", \"1\"], root= val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16223, 2560)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(trainX).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Validation accuracy: 83.44%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=2,\n",
    "\tn_jobs=-1, metric=\"manhattan\")\n",
    "model.fit(transformed_train_X, trainY)\n",
    "acc = model.score(transformed_valX, val_Y)\n",
    "print(\"[INFO] Validation accuracy: {:.2f}%\".format(acc * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Train accuracy: 91.46%\n"
     ]
    }
   ],
   "source": [
    "acc = model.score(transformed_train_X, trainY)\n",
    "\n",
    "print(\"[INFO] Train accuracy: {:.2f}%\".format(acc * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.863469483752096\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(30) # we need 2 principal components.\n",
    "pca.fit(trainX)\n",
    "transformed_train_X = pca.transform(trainX)\n",
    "print(np.sum(pca.explained_variance_ratio_) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "svclassifier = SVC()\n",
    "scores = cross_val_score(svclassifier, transformed_train_X, trainY, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89029276, 0.88320493, 0.8816641 , 0.88563502, 0.89025894])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_valX = pca.transform(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8925314271629283"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier.fit(transformed_train_X, trainY)\n",
    "val_score = svclassifier.score(transformed_valX, val_Y)\n",
    "val_score"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f85430522e24dcceb49f547c8042b2746187a0750be8e55b7097447c175006b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('keras-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
